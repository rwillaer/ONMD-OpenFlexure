#! /usr/bin/env python3
#  -*- coding: utf-8 -*-
#
# Support module generated by PAGE version 8.0
#  in conjunction with Tcl version 8.6
#    Jul 07, 2025 03:28:00 PM CEST  platform: Windows NT
#    Jul 08, 2025 02:30:21 PM CEST  platform: Windows NT
#    Jul 08, 2025 03:28:48 PM CEST  platform: Windows NT
#    Jul 10, 2025 05:55:52 PM CEST  platform: Windows NT
#    Jul 10, 2025 06:41:18 PM CEST  platform: Windows NT
#    Jul 11, 2025 07:29:23 AM CEST  platform: Windows NT
#    Jul 11, 2025 05:59:36 PM CEST  platform: Windows NT
#    Jul 12, 2025 11:27:11 AM CEST  platform: Windows NT
#    Jul 12, 2025 01:44:43 PM CEST  platform: Windows NT
#    Jul 12, 2025 02:51:35 PM CEST  platform: Windows NT
#    Jul 14, 2025 06:49:42 AM CEST  platform: Windows NT
#    Jul 15, 2025 04:03:18 PM CEST  platform: Windows NT
#    Jul 15, 2025 08:46:22 PM CEST  platform: Windows NT
#    Jul 16, 2025 05:51:43 PM CEST  platform: Windows NT
#    Jul 17, 2025 06:24:55 AM CEST  platform: Windows NT
#    Jul 17, 2025 07:20:59 AM CEST  platform: Windows NT
#    Jul 17, 2025 03:55:58 PM CEST  platform: Windows NT
#    Jul 19, 2025 04:42:53 PM CEST  platform: Windows NT
#    Jul 20, 2025 11:31:01 AM CEST  platform: Windows NT
#    Jul 20, 2025 03:02:10 PM CEST  platform: Windows NT
#    Jul 20, 2025 06:39:35 PM CEST  platform: Windows NT
#    Jul 20, 2025 06:48:26 PM CEST  platform: Windows NT
#    Jul 25, 2025 09:13:55 AM CEST  platform: Windows NT
#    Jul 25, 2025 05:54:36 PM CEST  platform: Windows NT
#    Jul 26, 2025 06:54:50 AM CEST  platform: Windows NT
#    Jul 26, 2025 11:54:52 AM CEST  platform: Windows NT
#    Jul 27, 2025 10:12:05 AM CEST  platform: Windows NT
#    Jul 29, 2025 01:27:49 PM CEST  platform: Windows NT
#    Jul 29, 2025 03:40:12 PM CEST  platform: Windows NT
#    Jul 29, 2025 04:19:31 PM CEST  platform: Windows NT
#    Aug 08, 2025 10:33:54 AM CEST  platform: Windows NT
#    Aug 25, 2025 06:36:32 AM CEST  platform: Windows NT
#    Aug 25, 2025 10:23:41 AM CEST  platform: Windows NT
#    Oct 28, 2025 08:06:17 AM CET  platform: Windows NT

import os

import subprocess

import sys

import cv2

import matplotlib.pyplot as plt
from matplotlib import cm
import matplotlib.patches as patches
from matplotlib.path import Path
from matplotlib.widgets import Cursor, PolygonSelector
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg
import matplotlib.image as mpimg
from matplotlib.widgets import Slider
import matplotlib.gridspec as gridspec
from matplotlib.widgets import RectangleSelector
import matplotlib.animation as animation
from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg

import numpy as np

from PIL import Image, ImageTk
from PIL import Image

import pandas as pd

from scipy.ndimage import binary_fill_holes

from skimage import measure
from skimage.morphology import (
    binary_closing, dilation, diamond, erosion, 
    remove_small_holes, remove_small_objects
)
from skimage.segmentation import clear_border
from skimage.measure import label, regionprops_table
from skimage.color import label2rgb
from skimage.feature import peak_local_max
from skimage.segmentation import watershed

import random

import tkinter as tk
import tkinter.ttk as ttk
from tkinter import filedialog, Tk
from tkinter.constants import *
from tkinter.messagebox import askyesno
from tkinter import messagebox

#-----------------

#-----------------

import PyONMD_Ana_02

_debug = True  # False to eliminate debug printing from callback functions.

# Global variable declaration
# !!!!!!!!!!!!  FFMPEG_PATH should be declared in f_Reduce_Movie and f_ConvertMovie_1 !!!!!!!!!!!!!
# Global variable declaration
# !!!!!!!!!!!!  FFMPEG_PATH should be declared in f_Reduce_Movie and f_ConvertMovie_1 !!!!!!!!!!!!!
total_frames = 0  # Initialize at module level
frame_first_gray=0 #mise à zero de la premiere image
BWfinal = None  # This should be your binary image (replace with actual image)
points = []
drawing = False
scale_factor = 0.5  # Adjust based on your screen size (0.5 = 50% scaling)
diff_image=None #mise à zero de la premiere image
thresholded_Diff_mask=None #masque de l'image diff
temp_Diff_mask=None #temporary Diff Image mask (after Dilatation or erosion)
global_blob_properties = None  # Add this line for storing blob properties

#-----------------------------------------------------------------------------
def main(*args):
    '''Main entry point for the application.'''
    global root, _top1, _w1
    
    root = tk.Tk()
    root.protocol('WM_DELETE_WINDOW', root.destroy)
    # Creates a toplevel widget.
    _top1 = root
    _w1 = PyONMD_Ana_02.Toplevel1(_top1)
    root.mainloop()
#-----------------------------------------------------------------------------

#----------------------------------------------------------------------
"""
def f_ConvertMovie_1():
    
    #Converts all H.264 (.h264) video files in a selected directory to MP4 format.
    #The output files are saved in the same directory as the input files.
    #Requires FFmpeg to be installed and available in the system PATH.
    
    # Initialize Tkinter root window (it won't be shown)

    print('f_Convert Movie_1 Activated')
    root = Tk()
    root.withdraw()
    
    # Ask user to select a directory
    input_dir = filedialog.askdirectory(title="Select directory containing H.264 files")
    if not input_dir:
        print("No directory selected. Exiting.")
        return
    
    # Find all .h264 files in the directory
    h264_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.h264')]
    
    if not h264_files:
        print(f"No H.264 files found in {input_dir}")
        return
    
    print(f"Found {len(h264_files)} H.264 file(s) to convert:")
    for file in h264_files:
        print(f" - {file}")
    
    # Ask for confirmation
    if not askyesno("Confirm Conversion", 
                   f"Convert {len(h264_files)} H.264 file(s) to MP4 in the same directory?"):
        print("Conversion cancelled.")
        return
    
    # Convert each file
    for filename in h264_files:
        input_path = os.path.join(input_dir, filename)
        output_path = os.path.join(input_dir, os.path.splitext(filename)[0] + '.mp4')
        
        print(f"\nConverting {filename} to MP4...")
        
        try:
            # FFmpeg command to convert H.264 to MP4
            cmd = [
                r"D:\Temporaire\Ffmpeg\ffmpeg-master-latest-win64-gpl-shared\bin\ffmpeg.exe",
                '-i', input_path,
                '-c', 'copy',
                '-f', 'mp4',
                '-y',
                output_path
            ]
            
            # Run FFmpeg command
            subprocess.run(cmd, check=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)
            print(f"Successfully converted {filename} to MP4")
            
        except subprocess.CalledProcessError as e:
            print(f"Error converting {filename}: {e.stderr.decode('utf-8') if e.stderr else str(e)}")
        except Exception as e:
            print(f"Unexpected error converting {filename}: {str(e)}")
    
    print("\nConversion process completed.")
"""
 #----------------------------------------------------------------------




 #----------------------------------------------------------------------
def f_ConvertMovie_1():
    """
    Converts all H.264 (.h264) video files in a selected directory to MP4 format.
    The output files are saved in the same directory as the input files.
    Requires FFmpeg path to be specified in the GUI entry field.
    """
    print('f_Convert Movie_1 Activated')
    root = Tk()
    root.withdraw()
    
    # Get FFmpeg path from the GUI entry
    ffmpeg_path = _w1.Entry29.get().strip()
    ffmpeg_path=os.path.join(ffmpeg_path, 'ffmpeg.exe')
    
    # Validate FFmpeg path
    if not ffmpeg_path:
        print("Error: No FFmpeg path specified. Please enter the path to ffmpeg.exe in the GUI.")
        showerror("Error", "No FFmpeg path specified. Please enter the path to ffmpeg.exe in the GUI.")
        return
    
    if not os.path.isfile(ffmpeg_path):
        print(f"Error: FFmpeg not found at specified path: {ffmpeg_path}")
        showerror("Error", f"FFmpeg not found at specified path:\n{ffmpeg_path}")
        return
    
    # Ask user to select a directory
    input_dir = filedialog.askdirectory(title="Select directory containing H.264 files")
    if not input_dir:
        print("No directory selected. Exiting.")
        return
    
    # Find all .h264 files in the directory
    h264_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.h264')]
    
    if not h264_files:
        print(f"No H.264 files found in {input_dir}")
        return
    
    print(f"Found {len(h264_files)} H.264 file(s) to convert:")
    for file in h264_files:
        print(f" - {file}")
    
    # Ask for confirmation
    if not askyesno("Confirm Conversion", 
                   f"Convert {len(h264_files)} H.264 file(s) to MP4 in the same directory?"):
        print("Conversion cancelled.")
        return
    
    # Convert each file
    for filename in h264_files:
        input_path = os.path.join(input_dir, filename)
        output_path = os.path.join(input_dir, os.path.splitext(filename)[0] + '.mp4')
        
        print(f"\nConverting {filename} to MP4...")
        
        try:
            # FFmpeg command to convert H.264 to MP4
            cmd = [
                ffmpeg_path,
                '-i', input_path,
                '-c', 'copy',
                '-f', 'mp4',
                '-y',
                output_path
            ]
            
            # Run FFmpeg command
            subprocess.run(cmd, check=True, stderr=subprocess.PIPE, stdout=subprocess.PIPE)
            print(f"Successfully converted {filename} to MP4")
            
        except subprocess.CalledProcessError as e:
            print(f"Error converting {filename}: {e.stderr.decode('utf-8') if e.stderr else str(e)}")
        except Exception as e:
            print(f"Unexpected error converting {filename}: {str(e)}")
    
    print("\nConversion process completed.")
 #----------------------------------------------------------------------






#-----------------------------------------------------------------------------
def f_Create_Movie(*args):
    print('Create Movie')

    # Get the directory where the script is located
    script_dir = os.path.dirname(os.path.abspath(__file__))
    
    # Parameters
    PartNb =  int(_w1.Entry23.get())
    PartArea = int(_w1.Entry24.get())
    PartIntens =  int(_w1.Entry25.get())
    BackGdIntens =int(_w1.Entry26.get())
    DispPixel =  float(_w1.Entry27.get())
    changeDirAfterNframes = float(_w1.Entry28.get())  # Change direction every N frames

    width, height = 1024, 900  # Frame dimensions
    total_frames = 300  # Total frames in movie
    output_file = os.path.join(script_dir, 'disks_movie.mp4')

    # Calculate radius from area (A = πr²)
    radius = int(np.sqrt(PartArea / np.pi))

    # Initialize disk positions and velocities
    positions = np.array([[random.randint(radius, width-radius), 
                        random.randint(radius, height-radius)] for _ in range(PartNb)], dtype=np.float64)
    velocities = np.array([[random.uniform(-DispPixel, DispPixel), 
                          random.uniform(-DispPixel, DispPixel)] for _ in range(PartNb)])

    # Create VideoWriter
    out = None
    try:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_file, fourcc, 30.0, (width, height), isColor=False)
        
        if not out.isOpened():
            fourcc = cv2.VideoWriter_fourcc(*'MJPG')
            out = cv2.VideoWriter(output_file, fourcc, 30.0, (width, height), isColor=False)
            
        if not out.isOpened():
            fourcc = cv2.VideoWriter_fourcc(*'XVID')
            out = cv2.VideoWriter(output_file, fourcc, 30.0, (width, height), isColor=False)
            
        if not out.isOpened():
            raise Exception("Could not initialize video writer")
            
    except Exception as e:
        print(f"Video writer initialization failed: {e}")
        out = None

    # Fallback to save frames as images if video writing fails
    frames_dir = os.path.join(script_dir, "frames")
    os.makedirs(frames_dir, exist_ok=True)
    save_as_images = (out is None)

    for frame_num in range(total_frames):
        # Randomly change velocities every changeDirAfterNframes
        if changeDirAfterNframes <= total_frames and (frame_num % changeDirAfterNframes == 0):
            velocities = np.array([[random.uniform(-DispPixel, DispPixel), 
                                  random.uniform(-DispPixel, DispPixel)] for _ in range(PartNb)])

        # Create blank frame
        frame = np.full((height, width), BackGdIntens, dtype=np.uint8)
        
        # Update positions with boundary checking
        positions += velocities
        for i in range(PartNb):
            # Bounce off walls
            if positions[i,0] <= radius or positions[i,0] >= width-radius:
                velocities[i,0] *= -1
            if positions[i,1] <= radius or positions[i,1] >= height-radius:
                velocities[i,1] *= -1
            
            # Ensure positions stay within bounds
            positions[i,0] = np.clip(positions[i,0], radius, width-radius)
            positions[i,1] = np.clip(positions[i,1], radius, height-radius)
            
            # Draw disk
            cv2.circle(frame, (int(round(positions[i,0])), int(round(positions[i,1]))), 
                      radius, PartIntens, -1)
        
        # Write frame
        if out is not None and out.isOpened():
            try:
                out.write(frame)
            except:
                print("Error writing frame to video, switching to image sequence")
                out.release()
                out = None
                save_as_images = True
                
        if save_as_images:
            cv2.imwrite(os.path.join(frames_dir, f"frame_{frame_num:04d}.png"), frame)

    # Clean up
    if out is not None and out.isOpened():
        out.release()
        print(f"Movie successfully saved as {output_file}")
    
    if save_as_images:
        print(f"Saved {total_frames} frames as PNG images in {frames_dir}")

    # If we saved images but wanted video, try ffmpeg to create video
    if save_as_images and not os.path.exists(output_file):
        try:
            import subprocess
            ffmpeg_cmd = [
                'ffmpeg',
                '-y',               # Overwrite without asking
                '-framerate', '30', # Frame rate
                '-i', os.path.join(frames_dir, 'frame_%04d.png'), # Input pattern
                '-c:v', 'libx264', # Codec
                '-pix_fmt', 'yuv420p', # Pixel format
                output_file
            ]
            subprocess.run(ffmpeg_cmd, check=True)
            print(f"Successfully created video using ffmpeg: {output_file}")
        except Exception as e:
            print(f"Could not create video with ffmpeg: {e}")

    # Display the created movie
    if os.path.exists(output_file):
        display_movie(output_file)
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def display_movie(movie_path):
    """Display the created movie using Matplotlib in a new window."""
    cap = cv2.VideoCapture(movie_path)
    
    if not cap.isOpened():
        print("Error: Could not open video file")
        return
    
    # Create figure and axis
    fig, ax = plt.subplots(figsize=(10, 7))
    plt.axis('off')
    plt.title("Generated Particle Movie")
    
    # Initialize with first frame
    ret, frame = cap.read()
    if not ret:
        print("Error: Could not read video")
        return
    
    # Convert to RGB if grayscale
    if len(frame.shape) == 2:
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
    else:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    img = ax.imshow(frame)
    
    def update_frame(i):
        cap.set(cv2.CAP_PROP_POS_FRAMES, i)
        ret, frame = cap.read()
        if ret:
            if len(frame.shape) == 2:
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)
            else:
                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img.set_array(frame)
        return img,
    
    # Calculate total frames and frame rate
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    # Create animation
    ani = animation.FuncAnimation(
        fig, 
        update_frame, 
        frames=total_frames,
        interval=1000/fps,  # ms between frames
        blit=True,
        repeat=True
    )
    
    plt.tight_layout()
    plt.show()
    cap.release()
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def show_nth_frame(pathMovie, nameMovie, nthFrame):
    """
    Opens the nth frame of an MP4 movie and displays it in a window.
    
    Args:
        pathMovie (str): Directory path where the movie is stored.
        nameMovie (str): Name of the MP4 file (including .mp4 extension).
        nthFrame (int): Frame number to extract (0-based index).
    """
    global total_frames  # Access the global variable
    
    # Construct full movie path
    movie_path = f"{pathMovie}/{nameMovie}"
    
    # Open the video file
    cap = cv2.VideoCapture(movie_path)
    
    if not cap.isOpened():
        print(f"Error: Could not open video file {movie_path}")
        return
    
    # Get total frames and store in global variable
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    if nthFrame >= total_frames:
        print(f"Error: Requested frame {nthFrame} exceeds total frames ({total_frames})")
        cap.release()
        return
    
    # Set the video position to the nth frame
    cap.set(cv2.CAP_PROP_POS_FRAMES, nthFrame)
    
    # Read the frame
    ret, frame = cap.read()
    
    if not ret:
        print(f"Error: Could not read frame {nthFrame}")
        cap.release()
        return
    
    
    # Convert OpenCV BGR image to RGB
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    # Convert to PhotoImage for Tkinter
    img = Image.fromarray(frame_rgb)
    img_tk = ImageTk.PhotoImage(image=img)

    """
    # Create a new Toplevel window
    img_window = tk.Toplevel(_top1)
    img_window.title(f"Frame {nthFrame} of {nameMovie}")
    
    # Display in a Label
    label = tk.Label(img_window, image=img_tk)
    label.image = img_tk  # Keep a reference!
    label.pack()
    cap.release()
    """

    #+++++++++++++
    plt.figure()
    plt.imshow(img, cmap='gray')
    plt.title('Original Image')
    plt.show()
    #+++++++++++++
#-----------------------------------------------------------------------------

def f_Button_1(*args):
    global total_frames  # Access the global variable
    print('Bouton 1 pressé')
    pathMovie = _w1.Entry1.get().strip()
    nameMovie = _w1.Entry2.get().strip()
    nthFrame = int(_w1.Entry3.get())
    _w1.nTotalFrames.set(total_frames)  # Update GUI with total frames
    show_nth_frame(pathMovie, nameMovie, nthFrame)

#def f_Button_2(*args):
#    print('Bouton 2 pressé')

def f_Button_3(*args):
    print('Bouton 3 pressé')

#-----------------------------------------------------------------------------
def f_DispFirstMinLast(*args):
    global total_frames,frame_first_gray  # Access the global variable
    print('Bouton first minus last bouton pressé')
    pathMovie = _w1.Entry1.get().strip()
    nameMovie = _w1.Entry2.get().strip()
    # Construct full movie path
    movie_path = f"{pathMovie}/{nameMovie}"
    
    # Open the video file once
    cap = cv2.VideoCapture(movie_path)
    if not cap.isOpened():
        print("Error: Could not open video file")
        return
    
    # Get first frame
    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)  # first frame is 0
    ret, frame_first = cap.read()
    if not ret:
        print("Error: Could not read first frame")
        cap.release()
        return
    
    
    # Get last frame
    cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames - 1)  # frames are 0-indexed
    ret, frame_last = cap.read()
    if not ret:
        print("Error: Could not read last frame")
        cap.release()
        return
    
    cap.release()
    
    # Convert to grayscale for difference calculation
    frame_first_gray = cv2.cvtColor(frame_first, cv2.COLOR_BGR2GRAY)
    frame_last_gray = cv2.cvtColor(frame_last, cv2.COLOR_BGR2GRAY)
    
    # Calculate absolute difference
    dif_frame = cv2.absdiff(frame_first_gray, frame_last_gray)
    
    # Apply jet colormap
    dif_frame_colored = cv2.applyColorMap(dif_frame, cv2.COLORMAP_JET)
    dif_frame_rgb = cv2.cvtColor(dif_frame_colored, cv2.COLOR_BGR2RGB)
    
    # Convert to PhotoImage for Tkinter
    img = Image.fromarray(dif_frame_rgb)
    img_tk = ImageTk.PhotoImage(image=img)
    
    """
    # Create a new Toplevel window
    img_window = tk.Toplevel(_top1)
    img_window.title(f"First-Last Frame Difference of {nameMovie}")
    
    # Display in a Label
    label = tk.Label(img_window, image=img_tk)
    label.image = img_tk  # Keep a reference!
    label.pack()
    """

    #+++++++++++++
    plt.figure()
    plt.imshow(img, cmap='jet')
    plt.title('First Minus Last Image')
    plt.show()
    #+++++++++++++

#-----------------------------------------------------------------------------
    
#-----------------------------------------------------------------------------
def f_DetectCells(*args):
    global frame_first_gray, filteredTemp
    print('Detect cells bouton pressé')

    # Load image
    I = frame_first_gray
    
    # Ensure image is grayscale (2D array)
    if len(I.shape) == 3:  # If it's a color image
        I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)
    
    # Step 1: Sobel edge detection with automatic threshold
    sobel_x = cv2.Sobel(I, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(I, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
    threshold = np.mean(gradient_magnitude)
    fudgeFactor = float(_w1.Entry4.get())
    BWs = gradient_magnitude > (threshold * fudgeFactor)
    BWs = BWs.astype(np.uint8) * 255

    # Step 2: Dilate with vertical and horizontal lines
    kernel_ver = np.array([[0, 1, 0]] * 3, dtype=np.uint8)
    kernel_hor = kernel_ver.T
    BWsdil = dilation(BWs, kernel_ver)
    BWsdil = dilation(BWsdil, kernel_hor)

    # Step 3: Fill holes
    BWdfill = remove_small_holes(BWsdil.astype(bool), area_threshold=128).astype(np.uint8) * 255

    # Step 4: Clear border
    BWnobord = clear_border(BWdfill.astype(bool)).astype(np.uint8) * 255

    # Step 5: Erode twice with diamond-shaped kernel
    seD = diamond(radius=1)
    filteredTemp = erosion(BWnobord, seD)
    filteredTemp = erosion(filteredTemp, seD)
    #filteredTemp=BWfinal

    # --- Find contours and draw them in red ---
    contours, _ = cv2.findContours(filteredTemp, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Convert grayscale 'I' to 3-channel RGB (for red overlay)
    if len(I.shape) == 2:
        I_rgb = cv2.cvtColor(I, cv2.COLOR_GRAY2RGB)
    else:
        I_rgb = I.copy()
    
    # Draw contours in red (BGR format)
    cv2.drawContours(I_rgb, contours, -1, (255, 0, 0), 1)  # Red contours, thickness=1px

    # --- Create all figures first ---
    plt.figure(1)
    plt.imshow(filteredTemp, cmap='gray')
    plt.title('Segmented Image (Binary)')

    plt.figure(2)
    plt.imshow(I, cmap='gray')
    plt.title('Original Image')

    plt.figure(3)
    plt.imshow(I_rgb)
    plt.title('Red Contours Overlay')

    # --- Show all figures at once ---
    plt.show()
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_Draw_Contours(ImageMask, ImageSource):
    # Make sure ImageMask is binary (0 and 255) and uint8
    if ImageMask.dtype != np.uint8:
        ImageMask = ImageMask.astype(np.uint8)
    if np.max(ImageMask) == 1:  # If binary is 0/1 instead of 0/255
        ImageMask = ImageMask * 255
    
    # Convert grayscale source to RGB if needed
    if len(ImageSource.shape) == 2:
        I_rgb = cv2.cvtColor(ImageSource, cv2.COLOR_GRAY2BGR)
    else:
        I_rgb = ImageSource.copy()
    
    # Find contours - ensure we're working with a binary image
    contours, _ = cv2.findContours(ImageMask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Draw contours in red (BGR format)
    cv2.drawContours(I_rgb, contours, -1, (0, 0, 255), 1)  # Note: BGR order for red
    
    # Display the result
    plt.figure(5)
    plt.imshow(cv2.cvtColor(I_rgb, cv2.COLOR_BGR2RGB))  # Convert BGR to RGB for matplotlib
    plt.title('Red Contours Overlay')
    plt.show()
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_AppMedFilt(*args):
    global frame_first_gray, filtered_image
    print('Apply Median Filter')

    kernel_size = int(_w1.Entry5.get())

    # Load image
    image = frame_first_gray
    
    # Check if the kernel size is odd
    if kernel_size % 2 == 0:
        kernel_size += 1
        print(f"Warning: Kernel size must be odd. Adjusted to {kernel_size}.")
    
    # Apply median filter
    filtered_image = cv2.medianBlur(image, kernel_size)
    
    # Convert to RGB for Tkinter
    filtered_rgb = cv2.cvtColor(filtered_image, cv2.COLOR_GRAY2RGB)
    
    # Convert to PhotoImage
    img = Image.fromarray(filtered_rgb)
    img_tk = ImageTk.PhotoImage(image=img)
    
    # Create a new Toplevel window
    img_window = tk.Toplevel(_top1)
    img_window.title("Median Filtered Image")
    
    # Display in a Label
    label = tk.Label(img_window, image=img_tk)
    label.image = img_tk  # Keep a reference!
    label.pack()
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_Acpt_Filt_Img(*args):
    global frame_first_gray, filtered_image
    print('Accept Filtered Image')
    frame_first_gray =filtered_image
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_Acpt_Mask(*args):
    global BWfinal, filteredTemp
    print ('Accept Mask')
    BWfinal=filteredTemp
    f_Draw_Contours(BWfinal, frame_first_gray)

#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_OrigImMaskFillHoles(*args):

    global filteredTemp
    print ('Fill holes button pressed')

    bw_image=filteredTemp

    """
    Fills holes (black pixels inside white blobs) in a binary image.
    Args:
        bw_image (numpy.ndarray): Binary image (0 = black, 255 = white).
    Returns:
        numpy.ndarray: Binary image with holes filled.
    """
    # Ensure input is binary (0 and 255)
    _, binary_mask = cv2.threshold(bw_image, 0, 255, cv2.THRESH_BINARY) 
    # Convert to boolean (True = white, False = black)
    binary_bool = binary_mask == 255 
    # Fill holes using SciPy
    filled_bool = binary_fill_holes(binary_bool)
    # Convert back to 0-255 format
    filled_image = np.where(filled_bool, 255, 0).astype(np.uint8)
    
    filteredTemp=filled_image

    # Figure 1: Binary mask
    plt.figure(1, figsize=(10, 6))
    plt.imshow(filteredTemp, cmap='gray')
    plt.title("Diff Image Mask After Holes Filling")
    plt.axis('off')
    plt.tight_layout()
    plt.show()
#------------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_Dilate(*args):
    print('Dilation')
    # Apply cyclic dilation using global variables and display result
    # Uses globals:
    # - DilErKernSize: radius of the disk SE
    # - EroodCycles: number of dilation cycles (using same variable as erosion)
    # - BWfinal: the binary image to process (uint8 with 0 and 255 values)
    
    global filteredTemp
    
    DilErKernSize = int(_w1.Entry6.get())
    DilateCycles = int(_w1.Entry8.get())

    if DilateCycles <= 0:
        dilated = filteredTemp.copy()
    else:
        # Create disk-shaped structuring element (same as erosion)
        kernel_diameter = 2 * DilErKernSize + 1
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_diameter, kernel_diameter))
        
        # Apply cyclic dilation (only change is using dilate instead of erode)
        dilated = filteredTemp.copy()
        for _ in range(DilateCycles):
            dilated = cv2.dilate(dilated, kernel)
    
    plt.figure(4)
    plt.imshow(dilated, cmap='gray')  # Added cmap='gray' for better binary display
    plt.title('Dilated Mask')
    # --- Show all figures at once ---
    plt.show()

    filteredTemp=dilated

    f_Draw_Contours(filteredTemp, frame_first_gray)
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_Erode(*args):
    print('Erosion')
    #Apply cyclic erosion using global variables and display result in Tkinter.
    #Returns eroded image and displays it.
    #Uses globals:
    #- DilErKernSize: radius of the disk SE
    #- EroodCycles: number of erosion cycles
    #- BWfinal: the binary image to process (uint8 with 0 and 255 values)
    
    global filteredTemp
    
    DilErKernSize = int(_w1.Entry6.get())
    EroodCycles = int(_w1.Entry7.get())

    if EroodCycles <= 0:
        eroded = filteredTemp.copy()
    else:
        # Create disk-shaped structuring element
        kernel_diameter = 2 * DilErKernSize + 1
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_diameter, kernel_diameter))
        
        # Apply cyclic erosion
        eroded = filteredTemp.copy()
        for _ in range(EroodCycles):
            eroded = cv2.erode(eroded, kernel)
    
    plt.figure(4)
    plt.imshow(eroded)
    plt.title('Eroded Mask')
    # --- Show all figures at once ---
    plt.show()

    filteredTemp=eroded

    f_Draw_Contours(eroded, frame_first_gray)
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_Blob_Analysis(*args):
    global BWfinal, frame_first_gray
    
    # Ensure images are properly formatted
    if BWfinal.dtype != np.uint8:
        BWfinal = BWfinal.astype(np.uint8)
    if np.max(BWfinal) == 1:
        BWfinal = BWfinal * 255
    
    if len(frame_first_gray.shape) == 3:  # If color image, convert to grayscale
        frame_first_gray = cv2.cvtColor(frame_first_gray, cv2.COLOR_BGR2GRAY)
    
    # Find all contours (blobs) in the image
    contours, _ = cv2.findContours(BWfinal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Initialize lists to store blob properties
    areas = []
    eccentricities = []
    intensities = []  # New list for intensity values
    
    # Create mask for blob regions
    blob_mask = np.zeros_like(BWfinal)
    cv2.drawContours(blob_mask, contours, -1, 255, thickness=cv2.FILLED)
    
    # Get intensities only in blob regions
    blob_intensities = frame_first_gray[blob_mask == 255]
    
    # Calculate properties for each blob
    for cnt in contours:
        # Area
        area = cv2.contourArea(cnt)
        areas.append(area)
        
        # Eccentricity
        if len(cnt) >= 5:
            (x, y), (MA, ma), angle = cv2.fitEllipse(cnt)
            eccentricity = np.sqrt(1 - (min(MA, ma)**2 / max(MA, ma)**2))
            eccentricities.append(eccentricity)
        
        # Intensity - create mask for individual blob
        blob_mask_indiv = np.zeros_like(BWfinal)
        cv2.drawContours(blob_mask_indiv, [cnt], -1, 255, thickness=cv2.FILLED)
        intensities.append(np.mean(frame_first_gray[blob_mask_indiv == 255]))
    
    # Calculate statistics
    stats = {
        "Total Blobs": len(contours),
        "Total Surface (px)": np.sum(areas),
        "Average Surface (px)": np.mean(areas) if areas else 0,
        "Surface Std (px)": np.std(areas) if areas else 0,
        "Average Eccentricity": np.mean(eccentricities) if eccentricities else 0,
        "Eccentricity Std": np.std(eccentricities) if eccentricities else 0,
        "Average Intensity": np.mean(intensities) if intensities else 0,
        "Intensity Std": np.std(intensities) if intensities else 0
    }
    
    # Create pandas DataFrame
    df = pd.DataFrame.from_dict(stats, orient='index', columns=['Value'])
    
    # Create figure with better layout for statistics table
    fig_table = plt.figure(figsize=(10, 5), num="Blob Statistics Table")
    ax_table = fig_table.add_subplot(111)
    ax_table.axis('off')
    
    # Create table with improved formatting
    table = plt.table(
        cellText=df.round(2).values,
        rowLabels=df.index,
        colLabels=df.columns,
        cellLoc='center',
        loc='center',
        bbox=[0.2, 0, 0.8, 1]  # [x0, y0, width, height]
    )
    
    # Adjust table style
    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1.2, 1.5)
    
    # Adjust column widths
    for key, cell in table.get_celld().items():
        if key[1] == -1:  # Header column
            cell.set_width(0.4)
    
    plt.title("Comprehensive Blob Statistics", y=1.1)
    plt.tight_layout()
    
    # Create visualization windows
    if areas:
        # Boxplot of Areas
        plt.figure("Area Boxplot", figsize=(6, 4))
        plt.boxplot(areas, vert=True, patch_artist=True)
        plt.title("Blob Area Distribution")
        plt.ylabel("Area (px)")
        plt.xticks([1], ['Areas'])
        
        # Histogram of Areas
        plt.figure("Area Histogram", figsize=(6, 4))
        plt.hist(areas, bins=20, edgecolor='black')
        plt.title("Blob Area Distribution")
        plt.xlabel("Area (px)")
        plt.ylabel("Frequency")
    
    if eccentricities:
        # Boxplot of Eccentricities
        plt.figure("Eccentricity Boxplot", figsize=(6, 4))
        plt.boxplot(eccentricities, vert=True, patch_artist=True)
        plt.title("Blob Eccentricity Distribution")
        plt.ylabel("Eccentricity")
        plt.ylim(0, 1)
        plt.xticks([1], ['Eccentricity'])
        
        # Histogram of Eccentricities
        plt.figure("Eccentricity Histogram", figsize=(6, 4))
        plt.hist(eccentricities, bins=20, edgecolor='black', range=(0, 1))
        plt.title("Blob Eccentricity Distribution")
        plt.xlabel("Eccentricity")
        plt.ylabel("Frequency")
    
    if intensities:
        # Boxplot of Intensities
        plt.figure("Intensity Boxplot", figsize=(6, 4))
        plt.boxplot(intensities, vert=True, patch_artist=True)
        plt.title("Blob Intensity Distribution")
        plt.ylabel("Intensity (0-255)")
        plt.xticks([1], ['Intensity'])
        
        # Histogram of Intensities
        plt.figure("Intensity Histogram", figsize=(6, 4))
        plt.hist(intensities, bins=20, edgecolor='black', range=(0, 255))
        plt.title("Blob Intensity Distribution")
        plt.xlabel("Intensity (0-255)")
        plt.ylabel("Frequency")
    
    # Save to Excel
    excel_filename = "blob_statistics_with_intensity.xlsx"
    df.to_excel(excel_filename)
    print(f"Statistics saved to {excel_filename}")
    
    plt.show()
    
    #return df, areas, eccentricities, intensities
#-----------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Acpt_Blobs(*args):
    global BWfinal

    BlobsMinArea=float(_w1.Entry9.get())
    BlobsMaxArea=float(_w1.Entry10.get())
    
    # Make sure BWfinal is binary (0 and 255) and uint8
    if BWfinal.dtype != np.uint8:
        BWfinal = BWfinal.astype(np.uint8)
    if np.max(BWfinal) == 1:
        BWfinal = BWfinal * 255
    
    # Create a blank mask to store filtered blobs
    filtered_mask = np.zeros_like(BWfinal)
    
    # Find all contours (blobs) in the image
    contours, _ = cv2.findContours(BWfinal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Filter contours by area
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if BlobsMinArea <= area <= BlobsMaxArea:
            # Draw the contour (filled) on our new mask
            cv2.drawContours(filtered_mask, [cnt], -1, 255, thickness=cv2.FILLED)
    
    # Update the global BWfinal with the filtered mask
    BWfinal = filtered_mask

    output_img_rgb = cv2.cvtColor(BWfinal, cv2.COLOR_BGR2RGB)
    
    # Optional: Display the result (you can remove this if not needed)
    #cv2.imshow('Filtered Blobs', output_img_rgb)
    #cv2.waitKey(1)  # Small delay to allow the window to update

    # Display with matplotlib
    plt.figure(4)
    plt.imshow(output_img_rgb)
    plt.title('Blob Areas on Grayscale Image')
    plt.show()
#------------------------------------------------------------------------------

#-----------------------------------------------------------------------
def f_Disp_Blob_Area():
    global BWfinal, frame_first_gray  # Access the global variables
    
    print('Display Blobs Area')
    """
    Calculate and display the area (in pixels) of each blob on the grayscale image (frame_first_gray).
    Displays the result using matplotlib with blob areas and contours in red.
    """
    # Make sure image is binary and uint8
    if BWfinal.dtype != np.uint8:
        BWfinal = BWfinal.astype(np.uint8)
    if np.max(BWfinal) == 1:
        BWfinal = BWfinal * 255
    
    # Convert grayscale image to 3-channel RGB for colored text
    if len(frame_first_gray.shape) == 2:
        output_img = cv2.cvtColor(frame_first_gray, cv2.COLOR_GRAY2BGR)
    else:
        output_img = frame_first_gray.copy()
    
    # Find contours (blobs)
    contours, _ = cv2.findContours(BWfinal, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Process each blob
    for cnt in contours:
        # Calculate area
        area = cv2.contourArea(cnt)
        
        # Get centroid position for text
        M = cv2.moments(cnt)
        if M["m00"] != 0:
            cX = int(M["m10"] / M["m00"])
            cY = int(M["m01"] / M["m00"])
        else:
            cX, cY = 0, 0
        
        # Draw contour in red
        cv2.drawContours(output_img, [cnt], -1, (0, 0, 255), 1)
        
        # Put text (area value) in red
        font = cv2.FONT_HERSHEY_SIMPLEX
        cv2.putText(output_img, f"{area}", (cX-20, cY), 
                   font, 0.4, (0, 0, 255), 1, cv2.LINE_AA)
    
    # Convert BGR to RGB for matplotlib display
    output_img_rgb = cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB)
    
    # Display with matplotlib
    plt.figure(4)
    plt.imshow(output_img_rgb)
    plt.title('Blob Areas on Grayscale Image')
    plt.show()

#----------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_SetRoiToO(*args): 
    global filteredTemp
    
    if filteredTemp is None:
        filteredTemp = np.ones((800, 1200), dtype=np.uint8) * 255  # Fallback image
    
    fig, ax = plt.subplots(figsize=(10, 8))
    ax.imshow(filteredTemp, cmap='gray')
    plt.title("Left-click to add points, Right-click to finish")

    # Store polygon vertices
    polygon_vertices = []

    def onselect(vertices):
        nonlocal polygon_vertices
        polygon_vertices = vertices
        print(f"Selected {len(vertices)} points")
        
        # Clear and redraw with current polygon
        ax.clear()
        ax.imshow(filteredTemp, cmap='gray')
        if len(vertices) > 1:
            ax.plot(*zip(*vertices), 'r-')  # Draw red line
            ax.plot(*vertices[-1], 'ro')    # Mark last point
        plt.draw()

    # Create selector with visible lines
    selector = PolygonSelector(ax, onselect,
                             props=dict(color='red', linewidth=2, alpha=0.5))
    
    plt.show()

    # Apply mask if polygon was drawn
    if len(polygon_vertices) > 2:
        h, w = filteredTemp.shape
        y, x = np.mgrid[:h, :w]
        coords = np.vstack((x.ravel(), y.ravel())).T
        mask = Path(polygon_vertices).contains_points(coords).reshape((h, w))
        filteredTemp[mask] = 0
        print("Mask applied successfully")

    # 3. Show result
    plt.imshow(filteredTemp, cmap='gray')
    plt.title("Result")
    plt.show()
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_CreateDiffImg(*args):
    global diff_image

    pathMovie = _w1.Entry1.get().strip()
    nameMovie = _w1.Entry2.get().strip()
    deltaFrames = int(_w1.Entry11.get())

    """
    Load a movie and highlight small displacements by frame differencing.
    
    Parameters:
    - pathMovie: str, path to the movie file
    - nameMovie: str, name of the movie file
    - deltaFrames: int, number of frames between the subtracted frames
    """
    # Construct the full movie path
    movie_path = f"{pathMovie}/{nameMovie}"
    
    # Open the video file
    cap = cv2.VideoCapture(movie_path)
    
    if not cap.isOpened():
        print(f"Error: Could not open video file {movie_path}")
        return
    
    # Read the first frame
    ret, prev_frame = cap.read()
    if not ret:
        print("Error: Could not read the first frame")
        return
    
    # Convert to grayscale for processing
    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
    
    # Initialize the difference accumulator
    diff_accumulator = np.zeros_like(prev_gray, dtype=np.float32)
    frame_count = 0
    
    while True:
        # Read the next frame
        ret, frame = cap.read()
        if not ret:
            break  # End of video
        
        # Convert to grayscale
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        frame_count += 1
        
        # Only process frames that are deltaFrames apart
        if frame_count % deltaFrames == 0:
            # Compute absolute difference
            frame_diff = cv2.absdiff(gray, prev_gray)
            # Accumulate the differences
            diff_accumulator += frame_diff.astype(np.float32)
            # Update the previous frame
            prev_gray = gray
    
    # Release the video capture object
    cap.release()
    
    if frame_count == 0:
        print("Error: No frames processed")
        return
    
    # Normalize the accumulated differences for display
    diff_image = diff_accumulator / frame_count
    #diff_image = np.uint8(255 * diff_image / np.max(diff_image))
    
    # Display with jet colormap
    plt.figure(figsize=(10, 8))
    plt.imshow(diff_image, cmap='jet')
    plt.colorbar(label='Displacement Intensity')
    plt.title(f"Accumulated Frame Differences (Δ={deltaFrames} frames)")
    plt.axis('off')
    plt.show()
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Cross_Section():
    global diff_image
    """
    Display an image in jet colormap, allow interactive point selection with mouse,
    draw a line between the points, and show the intensity profile along that line.
    
    Parameters:
    diff_image (2D numpy array): The image to display and analyze
    """
    
    # Create the figure and subplots
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))
    fig.suptitle('Interactive Cross-Section Tool')
    
    # Display the image on the first subplot
    im = ax1.imshow(diff_image, cmap='jet')
    ax1.set_title('Click two points on the image')
    plt.colorbar(im, ax=ax1, label='Intensity')
    ax1.grid(True, color='white', linestyle='--', linewidth=0.5, alpha=0.5)  # Grid for image
    
    # Initialize variables to store the clicked points
    points = []
    line = None
    intensity_profile = None
    
    def onclick(event):
        nonlocal points, line, intensity_profile
        
        # Only process clicks in the image axes
        if event.inaxes != ax1:
            return
            
        # Only process left mouse button clicks
        if event.button != 1:
            return
            
        # Get the click coordinates
        x, y = int(round(event.xdata)), int(round(event.ydata))
        points.append((x, y))
        
        # If we have two points, draw the line and profile
        if len(points) == 2:
            # Remove previous line if it exists
            if line is not None:
                line.remove()
                
            # Draw the line between points
            x_vals = [points[0][0], points[1][0]]
            y_vals = [points[0][1], points[1][1]]
            line, = ax1.plot(x_vals, y_vals, 'r-', linewidth=2)
            
            # Calculate the intensity profile along the line
            profile = get_line_profile(diff_image, points[0], points[1])
            
            # Update or create the profile plot
            if intensity_profile is not None:
                intensity_profile.set_ydata(profile)
                intensity_profile.set_xdata(np.arange(len(profile)))
                ax2.relim()
                ax2.autoscale_view()
            else:
                intensity_profile, = ax2.plot(profile, 'b-', linewidth=2)
                ax2.set_title('Intensity Profile Along Line')
                ax2.set_xlabel('Position along line')
                ax2.set_ylabel('Intensity')
                ax2.grid(True)  # Grid for profile plot
            
            fig.canvas.draw()
            
        # If we have more than two points, reset with the new point
        elif len(points) > 2:
            points = [points[-1]]  # Keep only the most recent point
    
    def get_line_profile(image, point1, point2):
        """Get the intensity profile along a line between two points"""
        x0, y0 = point1
        x1, y1 = point2
        
        # Get the number of samples along the line
        length = int(np.hypot(x1-x0, y1-y0))
        x, y = np.linspace(x0, x1, length), np.linspace(y0, y1, length)
        
        # Extract the values along the line (using nearest-neighbor interpolation)
        profile = image[y.astype(int), x.astype(int)]
        return profile
    
    # Connect the click event to the function
    fig.canvas.mpl_connect('button_press_event', onclick)
    
    # Add a cursor to help with point selection
    cursor = Cursor(ax1, useblit=True, color='white', linewidth=1)
    
    # Add grid to the profile plot (if not added during first plot)
    ax2.grid(True)
    
    plt.tight_layout()
    plt.show()
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Calc_Diff_Im_Tot_Pix(*args):
    global diff_image  

    sumPixDifImg=np.sum(diff_image)
    _w1.unMaskDifTotPix.set(sumPixDifImg)  # Update GUI with sum of pixels total frames 
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Set_Dif_Img_Thresh(*args):
    global diff_image, thresholded_Diff_mask
    
    # Check if diff_image exists
    if 'diff_image' not in globals() or diff_image is None:
        print("Error: diff_image not initialized!")
        return
    
    difImgThreshold = float(_w1.difImgThreshold.get())
    
    # Initialize thresholded_Diff_mask if needed
    if 'thresholded_Diff_mask' not in globals() or \
       thresholded_Diff_mask is None or \
       thresholded_Diff_mask.shape != diff_image.shape:
        thresholded_Diff_mask = np.zeros_like(diff_image, dtype=np.uint8)
    
    # Threshold the difference image
    thresholded_Diff_image = diff_image.copy()
    thresholded_Diff_image[thresholded_Diff_image < difImgThreshold] = 0
    
    # Update the mask (pixels above threshold = 255)
    thresholded_Diff_mask.fill(0)  # Reset to 0
    thresholded_Diff_mask[diff_image > difImgThreshold] = 255
    
    # Create three separate figures that will stay open
    plt.close('all')  # Close any existing figures
    
    # Figure 1: Thresholded difference image
    plt.figure(1, figsize=(10, 6))
    plt.imshow(thresholded_Diff_image, cmap='jet' if len(thresholded_Diff_image.shape) == 2 else None)
    plt.title(f"Thresholded (Threshold = {difImgThreshold})")
    plt.colorbar()
    plt.axis('off')
    
    # Figure 2: Binary mask
    plt.figure(2, figsize=(10, 6))
    plt.imshow(thresholded_Diff_mask, cmap='gray')
    plt.title(f"Diff Image Mask (Threshold = {difImgThreshold})")
    plt.axis('off')
    
    # Figure 3: Contours overlay
    plt.figure(3, figsize=(10, 6))
    plt.imshow(diff_image, cmap='jet')
    contours = measure.find_contours(thresholded_Diff_mask, 0.5)
    for contour in contours:
        plt.plot(contour[:, 1], contour[:, 0], linewidth=2, color='white')
    plt.title(f"Contours Overlay (Threshold = {difImgThreshold})")
    plt.colorbar()
    plt.axis('off')
    
    # Show all figures (non-blocking)
    plt.show(block=False)
#------------------------------------------------------------------------------

    
#------------------------------------------------------------------------------
def f_Check_Mov_Illum_Stab(*args):
    print ('Check Movie Illumination Stability button pressed')

    """
    Analyze illumination consistency throughout a movie by plotting frame intensities.
    
    Parameters:
    - pathMovie: Path to the movie file
    - nameMovie: Name of the movie file
    
    Returns:
    - frame_numbers: List of frame numbers
    - intensities: List of corresponding frame intensities
    - plot: Displays intensity vs frame number graph
    """

    pathMovie = _w1.Entry1.get().strip()
    nameMovie = _w1.Entry2.get().strip()

    # Combine path and filename
    movie_path = f"{pathMovie}/{nameMovie}" if pathMovie[-1] != '/' else f"{pathMovie}{nameMovie}"
    
    # Open the video file
    cap = cv2.VideoCapture(movie_path)
    
    if not cap.isOpened():
        print(f"Error: Could not open video file {movie_path}")
        return None, None
    
    # Get video properties
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)
    
    print(f"Analyzing {nameMovie} ({total_frames} frames, {fps:.2f} fps)")
    
    frame_numbers = []
    intensities = []
    
    # Process each frame
    for frame_idx in range(total_frames):
        ret, frame = cap.read()
        
        if not ret:
            print(f"Warning: Could not read frame {frame_idx}")
            continue
            
        # Convert to grayscale if needed
        if len(frame.shape) == 3:
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        else:
            gray = frame
            
        # Calculate total intensity
        total_intensity = np.sum(gray)
        
        # Store results
        frame_numbers.append(frame_idx)
        intensities.append(total_intensity)
        
        # Print progress every 10%
        if frame_idx % (total_frames // 10) == 0:
            print(f"Processed {frame_idx}/{total_frames} frames ({frame_idx/total_frames:.0%})")
    
    cap.release()
    
    # Plot the results
    plt.figure(figsize=(12, 6))
    plt.plot(frame_numbers, intensities, 'b-', linewidth=1)
    plt.title(f"Illumination Consistency: {nameMovie}")
    plt.xlabel("Frame Number")
    plt.ylabel("Total Intensity")
    plt.grid(True, alpha=0.3)
    
    # Calculate and display statistics
    mean_intensity = np.mean(intensities)
    std_intensity = np.std(intensities)
    cv = (std_intensity / mean_intensity) * 100  # Coefficient of variation
    
    stats_text = (f"Mean Intensity: {mean_intensity:.2e}\n"
                 f"Std Dev: {std_intensity:.2e}\n"
                 f"Coeff of Variation: {cv:.2f}%")
    
    plt.annotate(stats_text, xy=(0.02, 0.95), xycoords='axes fraction',
                bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))
    
    plt.tight_layout()
    plt.show()
    
    #return frame_numbers, intensities

# Example usage:
# frame_nums, intensities = check_illumination_consistency("/path/to/movie", "movie.mp4")
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Reduce_Movie():
    pathMovie = _w1.Entry1.get().strip()
    nameMovie = _w1.Entry2.get().strip()
    output_path = None
    MovieBegin = int(_w1.Entry13.get())
    MovieEnd = int(_w1.Entry14.get())
    output_path=None

    print ('Reduce Movie button pressed')

    """
    Reduce a video by keeping only frames between MovieBegin and MovieEnd using FFmpeg.
    
    Args:
        nameMovie (str): Name of the movie file (including extension)
        pathMovie (str): Path to the movie file
        MovieBegin (int): First frame to keep (0-based index)
        MovieEnd (int): Last frame to keep (0-based index, exclusive)
        output_path (str, optional): Output directory. Defaults to same as input.
    
    Returns:
        str: Path to the reduced movie file
    
    Requires:
        FFmpeg at C:\Temporaire\Ffmpeg\ffmpeg-master-latest-win64-gpl-shared\bin\ffmpeg.exe
    """
    # Path to FFmpeg executable (no PATH modification needed)
    #FFMPEG_PATH = r"C:\Temporaire\Ffmpeg\ffmpeg-master-latest-win64-gpl-shared\bin\ffmpeg.exe"
    #FFMPEG_PATH = r"D:\Temporaire\processing-4.0b2\tools\MovieMaker\tool\ffmpeg.exe"
    FFMPEG_PATH = _w1.Entry29.get().strip()
    FFMPEG_PATH=os.path.join(FFMPEG_PATH, 'ffmpeg.exe')


    
    # Construct full input and output paths
    input_file = os.path.join(pathMovie, nameMovie)
    
    if output_path is None:
        output_path = pathMovie
    
    # Generate output filename (appends "_reduced" before extension)
    base_name, ext = os.path.splitext(nameMovie)
    output_name = f"{base_name}_reduced{ext}"
    output_file = os.path.join(output_path, output_name)
    
    # Get video FPS using OpenCV (to calculate time positions)
    cap = cv2.VideoCapture(input_file)
    if not cap.isOpened():
        raise ValueError(f"Could not open video file: {input_file}")
    
    fps = cap.get(cv2.CAP_PROP_FPS)
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    cap.release()
    
    # Validate frame range
    if MovieBegin < 0 or MovieEnd > total_frames or MovieBegin >= MovieEnd:
        raise ValueError(f"Invalid frame range. Movie has {total_frames} frames.")
    
    # Calculate start time and duration in seconds
    start_time = MovieBegin / fps
    duration = (MovieEnd - MovieBegin) / fps
    
    # Build FFmpeg command
    cmd = [
        FFMPEG_PATH,
        "-ss", str(start_time),      # Start time (seconds)
        "-i", input_file,            # Input file
        "-t", str(duration),         # Duration (seconds)
        "-c:v", "libx264",           # Use H.264 video codec
        "-crf", "23",                # Quality (lower = better, 18-28 is typical)
        "-preset", "fast",           # Encoding speed/compression tradeoff
        "-c:a", "copy",              # Copy audio without re-encoding
        "-y",                        # Overwrite output if exists
        output_file
    ]
    
    # Run FFmpeg
    try:
        result = subprocess.run(cmd, check=True, capture_output=True, text=True)
    except subprocess.CalledProcessError as e:
        raise RuntimeError(f"FFmpeg failed with error:\n{e.stderr}")
    
    # Verify output file was created
    if not os.path.exists(output_file):
        raise RuntimeError("Output file was not created successfully")
    
    #return output_file
#------------------------------------------------------------------------------

    
#------------------------------------------------------------------------------
def f_AcceptDiffImgMask(*args):
    # Sets tem mask as definitive Diff Image mask
    global temp_Diff_mask, thresholded_Diff_mask
    thresholded_Diff_mask=temp_Diff_mask

    print ('Accept Diff Mask button pressed')

    # Figure 1: Binary mask
    plt.figure(1, figsize=(10, 6))
    plt.imshow(thresholded_Diff_mask, cmap='gray')
    plt.title("Diff Image Mask")
    plt.axis('off')
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_ErodeDiff(*args):
    global thresholded_Diff_mask, temp_Diff_mask
    display_result=True

    print ('Erode button pressed')

    """
    Applies repeated erosion operations on a binary image and optionally displays the result using Matplotlib.

    Parameters:
    - thresholded_Diff_mask: Binary input image (numpy array).
    - dIm_kernSize: Size of the square kernel for dilation (integer).
    - dIm_erodCycles: Number of times to repeat the dilation operation (integer).
    - display_result: If True, displays the original and dilated images using Matplotlib (default: True).

    Returns:
    - eroded_image: Resulting image after repeated dilations.
    """    

    dIm_kernSize = int(_w1.Entry15.get())
    dIm_erodeCycles = int(_w1.Entry16.get())

        # Ensure the input is a binary image (just in case)
    _, binary_mask = cv2.threshold(thresholded_Diff_mask, 0, 255, cv2.THRESH_BINARY)
    
    # Create a square kernel for dilation
    kernel = np.ones((dIm_kernSize, dIm_kernSize), np.uint8)
    
    # Apply dilation repeatedly
    eroded_image = binary_mask.copy()
    for _ in range(dIm_erodeCycles):
        eroded_image = cv2.erode(eroded_image, kernel, iterations=1)
    
    # Display results using Matplotlib if enabled
    if display_result:
        plt.figure(figsize=(10, 5))
        
        plt.subplot(1, 2, 1)
        plt.imshow(binary_mask, cmap='gray')
        plt.title('Original Binary Image')
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(eroded_image, cmap='gray')
        plt.title(f'Eroded Image (Kernel: {dIm_kernSize}, Cycles: {dIm_erodeCycles})')
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()

        temp_Diff_mask=eroded_image
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_DilDiff(): 
    global thresholded_Diff_mask, temp_Diff_mask
    display_result=True

    dIm_kernSize = int(_w1.Entry15.get())
    dIm_dilCycles = int(_w1.Entry17.get())

    print ('Dilate button pressed')

    """
    Applies repeated dilation operations on a binary image and optionally displays the result using Matplotlib.

    Parameters:
    - thresholded_Diff_mask: Binary input image (numpy array).
    - dIm_kernSize: Size of the square kernel for dilation (integer).
    - dIm_erodCycles: Number of times to repeat the dilation operation (integer).
    - display_result: If True, displays the original and dilated images using Matplotlib (default: True).

    Returns:
    - dilated_image: Resulting image after repeated dilations.
    """
    # Ensure the input is a binary image (just in case)
    _, binary_mask = cv2.threshold(thresholded_Diff_mask, 0, 255, cv2.THRESH_BINARY)
    
    # Create a square kernel for dilation
    kernel = np.ones((dIm_kernSize, dIm_kernSize), np.uint8)
    
    # Apply dilation repeatedly
    dilated_image = binary_mask.copy()
    for _ in range(dIm_dilCycles):
        dilated_image = cv2.dilate(dilated_image, kernel, iterations=1)
    
    # Display results using Matplotlib if enabled
    if display_result:
        plt.figure(figsize=(10, 5))
        
        plt.subplot(1, 2, 1)
        plt.imshow(binary_mask, cmap='gray')
        plt.title('Original Binary Image')
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(dilated_image, cmap='gray')
        plt.title(f'Dilated Image (Kernel: {dIm_kernSize}, Cycles: {dIm_dilCycles})')
        plt.axis('off')
        
        plt.tight_layout()
        plt.show()

        temp_Diff_mask=dilated_image
 #------------------------------------------------------------------------------   
    

 #------------------------------------------------------------------------------ 
def f_fill_blob_holes(*args):
    global thresholded_Diff_mask

    print ('Fill holes button pressed')

    bw_image=thresholded_Diff_mask

    """
    Fills holes (black pixels inside white blobs) in a binary image.
    Args:
        bw_image (numpy.ndarray): Binary image (0 = black, 255 = white).
    Returns:
        numpy.ndarray: Binary image with holes filled.
    """
    # Ensure input is binary (0 and 255)
    _, binary_mask = cv2.threshold(bw_image, 0, 255, cv2.THRESH_BINARY)
    
    # Convert to boolean (True = white, False = black)
    binary_bool = binary_mask == 255
    
    # Fill holes using SciPy
    filled_bool = binary_fill_holes(binary_bool)
    
    # Convert back to 0-255 format
    filled_image = np.where(filled_bool, 255, 0).astype(np.uint8)
    
    thresholded_Diff_mask=filled_image

    # Figure 1: Binary mask
    plt.figure(1, figsize=(10, 6))
    plt.imshow(thresholded_Diff_mask, cmap='gray')
    plt.title("Diff Image Mask After Holes Filling")
    plt.axis('off')
    plt.tight_layout()
    plt.show()
 #------------------------------------------------------------------------------ 

#------------------------------------------------------------------------------ 
def f_Ana_Bckgd(*args):
    global thresholded_Diff_mask, diff_image
 
    # Create a copy of the diff_image where blobs are set to 0
    diff_image_without_blobs = diff_image.copy()
    diff_image_without_blobs[thresholded_Diff_mask == 255] = 0
    
    # Calculate background statistics (excluding blobs)
    background_pixels = diff_image[thresholded_Diff_mask != 255]
    mean_value = np.mean(background_pixels)
    std_value = np.std(background_pixels)

    _w1.bck_Av_Val.set(mean_value)  # Update GUI dynamic Label
    _w1.bck_Std_Val.set(std_value)  # Update GUI dynamic Label

    # Plot 1: diff_image with blobs set to 0 (jet colormap)
    plt.figure(figsize=(8, 6))
    plt.imshow(diff_image_without_blobs, cmap='jet')
    plt.colorbar()
    plt.title('Diff Image (Blobs set to 0)')
    
    # Plot 2: Boxplot of background values
    plt.figure(figsize=(8, 6))
    # Ensure we're working with a 1D array and convert to list if needed
    flat_pixels = background_pixels.ravel()  # Flatten to 1D array
    plt.boxplot(flat_pixels, vert=True, patch_artist=True)
    plt.title(f'Background Stats\nMean: {mean_value:.2f}, Std: {std_value:.2f}')
    plt.ylabel('Pixel Value')
    
    # Plot 3: Histogram of background values
    plt.figure(figsize=(8, 6))
    plt.hist(flat_pixels, bins=50, edgecolor='black')
    plt.title('Background Pixel Distribution')
    plt.xlabel('Pixel Value')
    plt.ylabel('Frequency')
    
    # Show all figures
    plt.show()

#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_ana_ROI_Bckgnd(*args):

    global diff_image, thresholded_Diff_mask

    """
    Single-function solution to:
    1. Set blobs (mask=255) to 0 in `diff_image`.
    2. Let the user draw a polygonal ROI with the mouse.
    3. Compute ROI statistics (mean, std, min, max) and display a histogram + boxplot.
    
    Args:
        diff_image (np.ndarray): Input grayscale image.
        thresholded_Diff_mask (np.ndarray): Binary mask where blobs are 255.
    """
    # --- Step 1: Create image where blobs (mask=255) are set to 0 ---
    inverted_mask = np.where(thresholded_Diff_mask == 255, 0, 255).astype(np.uint8)
    blob_removed_img = np.where(inverted_mask == 255, diff_image, 0)
    
    # --- Step 2: Set up ROI selection with Matplotlib ---
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.set_title("Draw Polygon ROI (Right-click to close, Press 'Enter' to confirm)")
    ax.imshow(blob_removed_img, cmap='jet')
    
    roi_points = []  # Stores polygon vertices
    polygon_patch = None  # For dynamic polygon drawing
    
    def on_click(event):
        nonlocal roi_points, polygon_patch
        
        # Left-click: Add point
        if event.button == 1 and event.inaxes == ax:
            roi_points.append((event.xdata, event.ydata))
            
            # Update polygon visualization
            if polygon_patch:
                polygon_patch.remove()
            if len(roi_points) > 1:
                polygon = patches.Polygon(roi_points, closed=False, fill=False,
                                          edgecolor='red', linewidth=2)
                polygon_patch = ax.add_patch(polygon)
                fig.canvas.draw()
        
        # Right-click: Close polygon
        elif event.button == 3 and len(roi_points) >= 2:
            roi_points.append(roi_points[0])  # Close the loop
            if polygon_patch:
                polygon_patch.remove()
            polygon = patches.Polygon(roi_points, closed=True, fill=False,
                                     edgecolor='green', linewidth=2)
            polygon_patch = ax.add_patch(polygon)
            fig.canvas.draw()
    
    def on_key(event):
        if event.key == 'enter' and len(roi_points) >= 3:
            plt.close(fig)
            
            # --- Step 3: Analyze ROI ---
            # Create mask from polygon
            h, w = blob_removed_img.shape
            poly_path = Path(roi_points)
            x, y = np.meshgrid(np.arange(w), np.arange(h))
            coords = np.hstack((x.reshape(-1, 1), y.reshape(-1, 1)))
            mask = poly_path.contains_points(coords).reshape(h, w)
            
            # Extract ROI pixels
            roi_pixels = blob_removed_img[mask]
            
            # Compute statistics
            stats = {
                "mean": np.mean(roi_pixels),
                "std": np.std(roi_pixels),
                "min": np.min(roi_pixels),
                "max": np.max(roi_pixels),
            }
            
            print("\n--- ROI Statistics ---")
            for key, value in stats.items():
                print(f"{key}: {value:.2f}")
            
            # --- Step 4: Plot results ---

            meanROI=np.mean(roi_pixels)
            _w1.roi_bck_Av_Val.set(meanROI)  # Update GUI dynamic Label 
            stdROI=np.std(roi_pixels)
            _w1.roi_bck_Std_Val.set(stdROI)  # Update GUI dynamic Label 

            fig_results, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
            
            # Histogram
            ax1.hist(roi_pixels.ravel(), bins=50, color='blue', alpha=0.7)
            ax1.set_title("Pixel Intensity Histogram")
            ax1.set_xlabel("Intensity")
            ax1.set_ylabel("Frequency")
            
            # Boxplot
            ax2.boxplot(roi_pixels.ravel(), showmeans=True, patch_artist=True)
            ax2.set_title("Pixel Intensity Boxplot")
            ax2.set_ylabel("Intensity")
            
            plt.tight_layout()
            plt.show()
    
    # Connect event handlers
    fig.canvas.mpl_connect('button_press_event', on_click)
    fig.canvas.mpl_connect('key_press_event', on_key)
    plt.show()

#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Accept_Diff_Blobs(*args):

    global thresholded_Diff_mask

    BlobsMinArea=float(_w1.Entry18.get())
    BlobsMaxArea=float(_w1.Entry19.get())
    
    # Make sure BWfinal is binary (0 and 255) and uint8
    if thresholded_Diff_mask.dtype != np.uint8:
        thresholded_Diff_mask = thresholded_Diff_mask.astype(np.uint8)
    if np.max(thresholded_Diff_mask) == 1:
        thresholded_Diff_mask = thresholded_Diff_mask * 255
    
    # Create a blank mask to store filtered blobs
    filtered_mask = np.zeros_like(thresholded_Diff_mask)
    
    # Find all contours (blobs) in the image
    contours, _ = cv2.findContours(thresholded_Diff_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Filter contours by area
    for cnt in contours:
        area = cv2.contourArea(cnt)
        if BlobsMinArea <= area <= BlobsMaxArea:
            # Draw the contour (filled) on our new mask
            cv2.drawContours(filtered_mask, [cnt], -1, 255, thickness=cv2.FILLED)
    
    # Update the global BWfinal with the filtered mask
    thresholded_Diff_mask = filtered_mask

    output_img_rgb = cv2.cvtColor(thresholded_Diff_mask, cv2.COLOR_BGR2RGB)
    
    # Optional: Display the result (you can remove this if not needed)
    #cv2.imshow('Filtered Blobs', output_img_rgb)
    #cv2.waitKey(1)  # Small delay to allow the window to update

    # Display with matplotlib
    plt.figure(4)
    plt.imshow(output_img_rgb)
    plt.title('Blob Areas on Grayscale Image')
    plt.show()
#------------------------------------------------------------------------------
# 

# #------------------------------------------------------------------------------        
def f_Disp_Dif_Blob_Area(*args):
    global thresholded_Diff_mask, diff_image
    
    print('Display Blobs Area')
    
    # Check if images exist
    if thresholded_Diff_mask is None:
        print("Error: thresholded_Diff_mask is None! Check previous steps.")
        return
    if diff_image is None:
        print("Error: diff_image is None! Check previous steps.")
        return
    
    # Ensure thresholded_Diff_mask is a uint8 NumPy array
    if not isinstance(thresholded_Diff_mask, np.ndarray):
        thresholded_Diff_mask = np.array(thresholded_Diff_mask, dtype=np.uint8)
    elif thresholded_Diff_mask.dtype != np.uint8:
        thresholded_Diff_mask = thresholded_Diff_mask.astype(np.uint8)
    
    # Scale to 0-255 if binary (0-1)
    if np.max(thresholded_Diff_mask) == 1:
        thresholded_Diff_mask = thresholded_Diff_mask * 255
    
    # Create figure
    plt.figure(4)
    
    # Process based on image type
    if len(diff_image.shape) == 2:  # Grayscale
        # Display with jet colormap
        plt.imshow(diff_image, cmap='gray') #jet
        
        # Find contours
        contours, _ = cv2.findContours(thresholded_Diff_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        # Create a transparent overlay for contours
        overlay = np.zeros((*diff_image.shape[:2], 4), dtype=np.uint8)
        
        # Draw contours and labels on overlay
        for cnt in contours:
            area = cv2.contourArea(cnt)
            M = cv2.moments(cnt)
            cX = int(M["m10"] / M["m00"]) if M["m00"] != 0 else 0
            cY = int(M["m01"] / M["m00"]) if M["m00"] != 0 else 0
            
            # Draw contour (red with full opacity)
            cv2.drawContours(overlay, [cnt], -1, (255, 0, 0, 255), 2) # 255, 0, 0, 255
            
            # Put text (red with full opacity)
            cv2.putText(overlay, f"{area}", (cX-20, cY), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0, 255), 2, cv2.LINE_AA) #255, 0, 0, 255
        
        # Convert overlay to RGB and display
        plt.imshow(overlay)
        
    else:  # Color image
        output_img = diff_image.copy()
        contours, _ = cv2.findContours(thresholded_Diff_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        for cnt in contours:
            area = cv2.contourArea(cnt)
            M = cv2.moments(cnt)
            cX = int(M["m10"] / M["m00"]) if M["m00"] != 0 else 0
            cY = int(M["m01"] / M["m00"]) if M["m00"] != 0 else 0
            cv2.drawContours(output_img, [cnt], -1, (255, 255, 255), 2) # 0,0,255
            cv2.putText(output_img, f"{area}", (cX-20, cY), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 1, cv2.LINE_AA) # 0,0,255
        
        plt.imshow(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
    
    plt.colorbar(label='Intensity')
    plt.title('Blob Areas with Jet Colormap')
    plt.show()
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Anal_Diff_Blobs(*args):
    # Label the blobs in the binary mask
    labeled_mask = label(thresholded_Diff_mask)
    
    # Calculate region properties
    props = regionprops_table(labeled_mask, diff_image, 
                            properties=('label', 'area', 'eccentricity',
                                      'intensity_mean', 'intensity_std', 'intensity_max'))
    
    # Create DataFrame
    df = pd.DataFrame(props)
    df['intensity_mean_per_area'] = df['intensity_mean'] / df['area']
    df.columns = ['Blob Number', 'Area', 'Eccentricity', 
                 'Avg Intensity', 'Intensity Std', 'Max Intensity',
                 'Mean Intensity/Area']
    
    # Create display version with 4-digit formatting
    df_display = df.copy()
    float_cols = df_display.select_dtypes(include=['float64']).columns
    df_display[float_cols] = df_display[float_cols].round(4)
    
    # Create figure for table
    fig_table = plt.figure(figsize=(12, 8))
    ax = fig_table.add_subplot(111)
    ax.axis('off')
    
    # Display formatted table
    table = plt.table(cellText=df_display.values, 
                    colLabels=df_display.columns, 
                    loc='center',
                    cellLoc='center',
                    colColours=['#f3f3f3']*len(df_display.columns))
    
    # Formatting
    table.auto_set_font_size(False)
    table.set_fontsize(12)
    table.scale(1.2, 1.5)
    
    for (i, j), cell in table.get_celld().items():
        if i == 0:  # Header row
            cell.set_text_props(fontweight='bold', fontsize=14)
    
    plt.title('Blob Properties', fontsize=16, pad=20)
    plt.tight_layout()
    
    # Display labeled blobs
    fig_blobs = plt.figure(figsize=(10, 10))
    plt.imshow(label2rgb(labeled_mask, image=thresholded_Diff_mask, bg_label=0))
    plt.title('Labeled Blobs', fontsize=16)
    
    regions = regionprops_table(labeled_mask, properties=('label', 'centroid'))
    for i in range(len(regions['label'])):
        y, x = regions['centroid-0'][i], regions['centroid-1'][i]
        plt.text(x, y, str(regions['label'][i]), 
                color='red', ha='center', va='center',
                fontsize=12, fontweight='bold')
    
    # Write to Excel file at the specified directory
    try:
        # Get the directory path from the Entry widget
        directory_path = _w1.Entry1.get().strip()
        
        # If the path is empty, use current directory
        if not directory_path:
            directory_path = "."
            print("No path specified in Entry1, using current directory")
        
        # Create directory if it doesn't exist
        import os
        if not os.path.exists(directory_path):
            os.makedirs(directory_path)
            print(f"Created directory: {directory_path}")
        
        # Create the full file path
        filename = "blob_analysis.xlsx"
        full_path = os.path.join(directory_path, filename)
        
        # Write DataFrame to Excel
        df.to_excel(full_path, index=False, float_format="%.4f")
        print(f"Data successfully exported to: {full_path}")
        
    except Exception as e:
        print(f"Error exporting to Excel: {e}")
    
    plt.show()
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
def f_Ana_Blob_f_Time(*args):
    # Get parameters from GUI
    nameMovie = _w1.Entry2.get().strip()
    pathMovie = _w1.Entry1.get().strip()
    fudgeFactor = float(_w1.Entry4.get())
    BlobsMinArea = float(_w1.Entry9.get())
    BlobsMaxArea = float(_w1.Entry10.get())
    
    # Construct full movie path
    pathMovie = f"{pathMovie}/{nameMovie}"
    
    # Open video file with different backends if needed
    print(f"Attempting to open video file at: {pathMovie}")
    cap = cv2.VideoCapture(pathMovie)
    
    # Try different backends if default fails
    if not cap.isOpened():
        print("Default backend failed, trying CAP_DSHOW...")
        cap = cv2.VideoCapture(pathMovie, cv2.CAP_DSHOW)
    
    if not cap.isOpened():
        print("CAP_DSHOW failed, trying CAP_MSMF...")
        cap = cv2.VideoCapture(pathMovie, cv2.CAP_MSMF)
    
    if not cap.isOpened():
        print("CAP_MSMF failed, trying CAP_ANY...")
        cap = cv2.VideoCapture(pathMovie, cv2.CAP_ANY)
    
    if not cap.isOpened():
        error_msg = f"Error: Could not open video file at {pathMovie} with any backend"
        print(error_msg)
        messagebox.showerror("Video Error", error_msg)
        return None  # Return None to indicate failure
    
    print("Video opened successfully!")
    
    # Close any existing matplotlib figures
    plt.close('all')
    
    # Initialize variables for tracking
    blob_paths = {}
    blob_properties = {}
    frame_count = 0
    
    # Create new figure for visualization
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7), num="Blob Tracking Analysis")
    fig.suptitle(f'Blob Tracking Analysis - {nameMovie}')
    plt.ion()
    plt.show()
    
    try:
        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                print(f"Reached end of video at frame {frame_count}")
                break
            
            # Convert frame to grayscale
            if len(frame.shape) == 3:
                frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            else:
                frame_gray = frame.copy()
            
            # Detect blobs using the provided algorithm
            BWfinal = detect_blobs(frame_gray, fudgeFactor)
            
            # Fill holes in blobs
            filled_image = fill_holes(BWfinal)
            
            # Find and filter blobs by area
            current_blobs = find_and_filter_blobs(filled_image, BlobsMinArea, BlobsMaxArea)
            
            # Track blobs and update paths
            if frame_count == 0:
                # Initialize tracking for first frame
                for i, blob in enumerate(current_blobs):
                    blob_id = i + 1
                    centroid = blob['centroid']
                    blob_paths[blob_id] = [centroid]
                    blob_properties[blob_id] = {
                        'areas': [blob['area']],
                        'displacements': [0],  # No displacement for first frame
                        'total_displacement': 0
                    }
                print(f"Initialized tracking with {len(current_blobs)} blobs")
            else:
                # For subsequent frames, match blobs with previous ones
                updated_blobs = {}
                matched = set()
                
                # Simple nearest neighbor matching
                for blob_id, path in blob_paths.items():
                    last_centroid = path[-1]
                    min_dist = float('inf')
                    best_match = None
                    
                    for blob in current_blobs:
                        if blob['id'] in matched:
                            continue
                        
                        dist = np.sqrt((last_centroid[0] - blob['centroid'][0])**2 + 
                                      (last_centroid[1] - blob['centroid'][1])**2)
                        
                        if dist < min_dist and dist < 20:  # Max allowed movement between frames
                            min_dist = dist
                            best_match = blob
                    
                    if best_match:
                        updated_blobs[blob_id] = best_match
                        matched.add(best_match['id'])
                
                # Update paths and properties
                for blob_id, path in blob_paths.items():
                    if blob_id in updated_blobs:
                        blob = updated_blobs[blob_id]
                        new_centroid = blob['centroid']
                        last_centroid = path[-1]
                        
                        # Calculate displacement from last position
                        displacement = np.sqrt((new_centroid[0] - last_centroid[0])**2 + 
                                        (new_centroid[1] - last_centroid[1])**2)
                        
                        # Update path and properties
                        path.append(new_centroid)
                        blob_properties[blob_id]['areas'].append(blob['area'])
                        blob_properties[blob_id]['displacements'].append(displacement)
                        blob_properties[blob_id]['total_displacement'] += displacement
                    else:
                        # Blob disappeared, keep last position
                        path.append(path[-1])
                        blob_properties[blob_id]['areas'].append(blob_properties[blob_id]['areas'][-1])
                        blob_properties[blob_id]['displacements'].append(0)
                
                # Add new blobs that appeared in this frame
                for blob in current_blobs:
                    if blob['id'] not in matched:
                        new_id = max(blob_paths.keys()) + 1 if blob_paths else 1
                        blob_paths[new_id] = [blob['centroid']]
                        blob_properties[new_id] = {
                            'areas': [blob['area']],
                            'displacements': [0],
                            'total_displacement': 0
                        }
            
            # Update visualization every N frames or at the end
            if frame_count % 5 == 0 or frame_count == int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) - 1:
                update_visualization(ax1, ax2, frame_gray, blob_paths, blob_properties, frame_count)
                plt.pause(0.01)
            
            frame_count += 1
            
            if frame_count % 50 == 0:
                print(f"Processed {frame_count} frames...")
        
    except Exception as e:
        print(f"Error during processing: {str(e)}")
        import traceback
        traceback.print_exc()
    finally:
        cap.release()
        plt.ioff()
        
        # Display final results if we processed any frames
        if frame_count > 0 and blob_properties:
            print(f"Tracking completed. Processed {frame_count} frames, tracked {len(blob_properties)} blobs")
            display_results_table(blob_properties, pathMovie)
            plt.show()
            
            # Store blob_properties globally for later use
            global global_blob_properties
            global_blob_properties = blob_properties
            print("Blob properties stored globally for violin plots")
            
        else:
            error_msg = "No frames were processed or no blobs were tracked"
            print(error_msg)
            messagebox.showinfo("No Data", error_msg)
    
    return blob_properties

def detect_blobs(image, fudgeFactor):
    """Detect blobs using the provided algorithm"""
    # Step 1: Sobel edge detection with automatic threshold
    sobel_x = cv2.Sobel(image, cv2.CV_64F, 1, 0, ksize=3)
    sobel_y = cv2.Sobel(image, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)
    threshold = np.mean(gradient_magnitude)
    BWs = gradient_magnitude > (threshold * fudgeFactor)
    BWs = BWs.astype(np.uint8) * 255

    # Step 2: Dilate with vertical and horizontal lines
    kernel_ver = np.array([[0, 1, 0]] * 3, dtype=np.uint8)
    kernel_hor = kernel_ver.T
    BWsdil = dilation(BWs, kernel_ver)
    BWsdil = dilation(BWsdil, kernel_hor)

    # Step 3: Fill holes
    BWdfill = remove_small_holes(BWsdil.astype(bool), area_threshold=128).astype(np.uint8) * 255

    # Step 4: Clear border
    BWnobord = clear_border(BWdfill.astype(bool)).astype(np.uint8) * 255

    # Step 5: Erode twice with diamond-shaped kernel
    seD = diamond(radius=1)
    BWfinal = erosion(BWnobord, seD)
    BWfinal = erosion(BWfinal, seD)
    
    return BWfinal

def fill_holes(bw_image):
    """Fill holes in binary image"""
    _, binary_mask = cv2.threshold(bw_image, 0, 255, cv2.THRESH_BINARY) 
    binary_bool = binary_mask == 255 
    filled_bool = binary_fill_holes(binary_bool)
    filled_image = np.where(filled_bool, 255, 0).astype(np.uint8)
    return filled_image

def find_and_filter_blobs(image, min_area, max_area):
    """Find connected components and filter by area"""
    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(image, connectivity=8)
    
    blobs = []
    for i in range(1, num_labels):  # Skip background (0)
        area = stats[i, cv2.CC_STAT_AREA]
        if min_area <= area <= max_area:
            x, y = centroids[i]
            bbox = stats[i, :4]  # x, y, width, height
            blobs.append({
                'id': i,
                'area': area,
                'centroid': (x, y),
                'bbox': bbox
            })
    
    return blobs

def update_visualization(ax1, ax2, frame, blob_paths, blob_properties, frame_count):
    """Update the visualization plots with blob numbers (no legends)"""
    # Clear axes
    ax1.clear()
    ax2.clear()
    
    # Plot 1: Current frame with blob paths
    ax1.imshow(frame, cmap='gray', origin='upper')
    ax1.set_title(f'Frame {frame_count} with Blob Paths')
    
    # Get color map for blobs
    colors = plt.cm.get_cmap('hsv', len(blob_paths) + 1)
    
    # Plot each blob's path and add number labels
    for i, (blob_id, path) in enumerate(blob_paths.items()):
        if len(path) > 0:
            # Handle both single-point and multi-point paths
            if len(path) > 1:
                xs, ys = zip(*path)
                ax1.plot(xs, ys, '-', color=colors(i), linewidth=2)
            else:
                xs, ys = [path[0][0]], [path[0][1]]
            
            # Plot current position
            ax1.plot(xs[-1], ys[-1], 'o', color=colors(i), markersize=8)
            
            # Add blob number label (5 pixels offset from current position)
            ax1.text(xs[-1] + 5, ys[-1] + 5, str(blob_id),
                    color='white', fontsize=10, weight='bold',
                    bbox=dict(facecolor=colors(i), alpha=0.8, 
                             edgecolor='none', boxstyle='round'))
    
    # Plot 2: All paths in a single graph
    ax2.set_title('All Blob Paths (Image Coordinates)')
    ax2.set_xlabel('X position (pixels)')
    ax2.set_ylabel('Y position (pixels)')
    ax2.invert_yaxis()  # Match image coordinates
    
    for i, (blob_id, path) in enumerate(blob_paths.items()):
        if len(path) > 1:
            xs, ys = zip(*path)
            ax2.plot(xs, ys, '-', color=colors(i), linewidth=2)
            ax2.plot(xs[0], ys[0], 'o', color=colors(i), markersize=8)  # Start point
            ax2.plot(xs[-1], ys[-1], 's', color=colors(i), markersize=8)  # End point
            
            # Add blob number near the end point
            ax2.text(xs[-1] + 5, ys[-1] + 5, str(blob_id),
                    color='white', fontsize=10, weight='bold',
                    bbox=dict(facecolor=colors(i), alpha=0.8,
                    edgecolor='none', boxstyle='round'))
    
    ax2.grid(True)
    ax2.set_aspect('equal', adjustable='datalim')
    
    plt.tight_layout()

#------------------------------
def display_results_table(blob_properties, movie_path=None):
    """Display a table with the results and save to Excel"""
    # Store blob_properties globally
    global global_blob_properties
    global_blob_properties = blob_properties
    
    # Create the table data first
    columns = ["Blob ID", "Total Displacement", "Max Displacement", "Avg Displacement", "Path Length"]
    table_data = []
    
    for blob_id, props in blob_properties.items():
        displacements = props['displacements']
        total_disp = props['total_displacement']
        max_disp = max(displacements) if displacements else 0
        avg_disp = np.mean(displacements) if displacements else 0
        path_length = len(props['displacements'])
        
        table_data.append([
            blob_id,
            round(total_disp, 2),
            round(max_disp, 2),
            round(avg_disp, 2),
            path_length
        ])
    
    # Save to Excel if movie path is provided
    if movie_path:
        try:
            # Get directory from movie path
            output_dir = os.path.dirname(movie_path)
            
            # Create filename with timestamp
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            excel_filename = f"Blobs_Displ_Data_{timestamp}.xlsx"
            excel_path = os.path.join(output_dir, excel_filename)
            
            # Create DataFrame and save
            df = pd.DataFrame(table_data, columns=columns)
            df.to_excel(excel_path, index=False)
            
            # Show success message
            messagebox.showinfo(
                "Success", 
                f"Data saved successfully to:\n{excel_path}"
            )
        except Exception as e:
            messagebox.showerror(
                "Error", 
                f"Could not save Excel file:\n{str(e)}"
            )
    
    # Create and display the GUI table
    root = tk.Tk()
    root.title("Blob Displacement Results")
    
    frame = ttk.Frame(root)
    frame.pack(fill=tk.BOTH, expand=True)
    
    tree = ttk.Treeview(frame, columns=columns, show="headings")
    
    for col in columns:
        tree.heading(col, text=col)
        tree.column(col, width=100, anchor=tk.CENTER)
    
    for row in table_data:
        tree.insert("", tk.END, values=row)
    
    scrollbar = ttk.Scrollbar(frame, orient=tk.VERTICAL, command=tree.yview)
    tree.configure(yscroll=scrollbar.set)
    scrollbar.pack(side=tk.RIGHT, fill=tk.Y)
    tree.pack(fill=tk.BOTH, expand=True)
    
    # Add buttons frame
    btn_frame = ttk.Frame(root)
    btn_frame.pack(pady=10)
    
    # Add save button if not already saved
    if not movie_path:
        save_btn = ttk.Button(
            btn_frame, 
            text="Save to Excel", 
            command=lambda: save_to_excel(table_data, columns)
        )
        save_btn.pack(side=tk.LEFT, padx=5)
    
    # Add heatmap button
    heatmap_btn = ttk.Button(
        btn_frame,
        text="Show Displacement Heatmap",
        command=lambda: f_Blobs_Displ_Heatmap(blob_properties)
    )
    heatmap_btn.pack(side=tk.LEFT, padx=5)
    
    # Add violin plot button - use the global blob_properties
    violin_btn = ttk.Button(
        btn_frame,
        text="Show Displacement Violin Plots",
        command=f_ViolinPlots  # Updated function name
    )
    violin_btn.pack(side=tk.LEFT, padx=5)
    
    # Add debug button to check blob_properties
    debug_btn = ttk.Button(
        btn_frame,
        text="Debug Info",
        command=lambda: print(f"Blob properties keys: {list(global_blob_properties.keys()) if global_blob_properties else 'None'}")
    )
    debug_btn.pack(side=tk.LEFT, padx=5)

#++++++++++++++++++++++++++++++++++++++++++
    debug_btn = ttk.Button(
        btn_frame,
        text="Debug Blob Data",
        command=f_Debug_Blob_Data
    )
    debug_btn.pack(side=tk.LEFT, padx=5)
#++++++++++++++++++++++++++++++++++++++++++

    
    root.mainloop()   #<-----------------------------------------------------------------------------
#---------------------------------

def save_to_excel(table_data, columns):
    """Helper function to handle Excel saving"""
    from tkinter import filedialog
    try:
        # Ask for save location
        filepath = filedialog.asksaveasfilename(
            defaultextension=".xlsx",
            filetypes=[("Excel files", "*.xlsx")],
            initialfile="Blobs_Displ_Data.xlsx"
        )
        
        if filepath:
            df = pd.DataFrame(table_data, columns=columns)
            df.to_excel(filepath, index=False)
            messagebox.showinfo("Success", f"Data saved to:\n{filepath}")
    except Exception as e:
        messagebox.showerror("Error", f"Could not save file:\n{str(e)}")
   
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
def f_Parameters_Explanation(*args):
    """Display a window explaining the blob tracking parameters"""
    root = tk.Tk()
    root.title("Parameter Explanation")
    root.geometry("700x600")
    
    # Create main frame with scrollbar
    main_frame = ttk.Frame(root)
    main_frame.pack(fill=tk.BOTH, expand=True)
    
    # Create canvas and scrollbar
    canvas = tk.Canvas(main_frame)
    scrollbar = ttk.Scrollbar(main_frame, orient="vertical", command=canvas.yview)
    scrollable_frame = ttk.Frame(canvas)
    
    # Configure canvas scrolling
    scrollable_frame.bind(
        "<Configure>",
        lambda e: canvas.configure(
            scrollregion=canvas.bbox("all")
        )
    )
    canvas.create_window((0, 0), window=scrollable_frame, anchor="nw")
    canvas.configure(yscrollcommand=scrollbar.set)
    
    # Pack widgets
    canvas.pack(side="left", fill="both", expand=True)
    scrollbar.pack(side="right", fill="y")
    
    # Content with formatted text
    content = [
        ("1. Blob ID:", [
            "- A unique identifier for each tracked blob",
            "- Numbers correspond to the labels shown on your visualization plots",
            "- Helps you match table rows with specific blobs in your images"
        ]),
        ("2. Total Displacement:", [
            "- The cumulative distance traveled by the blob across all frames",
            "- Calculated as the sum of all frame-to-frame displacements",
            "- Measured in pixels",
            "- Indicates overall movement activity of each blob"
        ]),
        ("3. Max Displacement:", [
            "- The largest single frame-to-frame movement observed for the blob",
            "- Shows the maximum instantaneous speed/distance traveled between two consecutive frames",
            "- Helps identify sudden movements or tracking anomalies"
        ]),
        ("4. Avg Displacement:", [
            "- The average distance traveled per frame",
            "- Calculated as total displacement divided by number of frames",
            "- Gives a sense of the blob's typical movement behavior",
            "- Useful for comparing general mobility between blobs"
        ]),
        ("5. Path Length:", [
            "- The number of frames where the blob was detected",
            "- Indicates tracking duration/stability",
            "- A count equal to your total frame count means the blob persisted throughout",
            "- Lower counts may indicate temporary or disappearing/reappearing blobs"
        ]),
        ("Technical Notes:", [
            "- All displacement values are in pixels",
            "- Values are displayed with 2 decimal places for precision",
            "- The table is scrollable if many blobs are present",
            "- Data comes from the `blob_properties` dictionary accumulated during tracking"
        ]),
        ("Interpretation Tips:", [
            "- Higher total displacement = more active/mobile blob",
            "- Large max displacement might indicate tracking errors or real rapid movements",
            "- Similar avg displacements suggest consistent movement patterns",
            "- Compare path lengths to see which blobs were tracked longest"
        ]),
        ("Summary:", [
            "The table gives you a quantitative summary of each blob's movement characteristics",
            "throughout your entire video sequence."
        ])
    ]
    
    # Add content to the scrollable frame
    for header, items in content:
        # Header with bold font
        header_label = ttk.Label(scrollable_frame, text=header, 
                               font=('TkDefaultFont', 10, 'bold'), 
                               justify=tk.LEFT)
        header_label.pack(anchor='w', padx=10, pady=(10, 0))
        
        # Bullet points
        for item in items:
            item_label = ttk.Label(scrollable_frame, text=item, 
                                 justify=tk.LEFT)
            item_label.pack(anchor='w', padx=20, pady=(0, 0))
    
    root.mainloop()

#------------------------------------------------------------------------------    

#------------------------------------------------------------------------------ 
def f_Blobs_Displ_Heatmap(blob_properties):

    """Create a heatmap visualization of blob displacements over time"""
    # Create a new figure window
    plt.figure(figsize=(12, 8))
    
    # Prepare data for heatmap
    blob_ids = sorted(blob_properties.keys())
    max_frames = max(len(props['displacements']) for props in blob_properties.values())
    
    # Create displacement matrix (blobs x frames)
    displacement_matrix = np.zeros((len(blob_ids), max_frames))
    
    for i, blob_id in enumerate(blob_ids):
        props = blob_properties[blob_id]
        num_frames = len(props['displacements'])
        displacement_matrix[i, :num_frames] = props['displacements']
    
    # Create heatmap
    plt.imshow(displacement_matrix, cmap='jet', aspect='auto', 
              interpolation='nearest', origin='lower')
    
    # Add colorbar
    cbar = plt.colorbar()
    cbar.set_label('Displacement (pixels)', fontsize=12)
    
    # Customize axes
    plt.xlabel('Frame Number', fontsize=12)
    plt.ylabel('Blob ID', fontsize=12)
    plt.title('Blob Displacements Over Time', fontsize=14)
    
    # Set tick labels
    plt.yticks(np.arange(len(blob_ids)), blob_ids)
    
    # Add grid
    plt.grid(True, linestyle=':', color='white', alpha=0.3)
    
    plt.tight_layout()
    plt.show()
#------------------------------------------------------------------------------ 

#-----------------------------------------------------------------------------
def f_Watershade_Seg():
    global BWfinal
    """
    Extended watershed segmentation with:
    - Three separate figures (overlay, numbered particles, results table)
    - Particle measurements (area, eccentricity, intensity)
    - Excel export
    - Scrollable table for large datasets
    - Limited to 4 decimal places in table
    - Fixed tight_layout warning
    """
    binary_mask = BWfinal
    pathMovie = _w1.Entry1.get().strip()
    nameMovie = _w1.Entry2.get().strip()
    nthFrame = int(_w1.Entry3.get())

    # Construct full movie path
    movie_path = os.path.join(pathMovie, nameMovie)
    
    # Open the video file
    cap = cv2.VideoCapture(movie_path)
    
    # Check if video opened successfully
    if not cap.isOpened():
        print("Error: Could not open video file")
        return None, None
    
    # Set the frame position
    cap.set(cv2.CAP_PROP_POS_FRAMES, nthFrame)
    
    # Read the specific frame
    ret, frame = cap.read()
    cap.release()  # Release the video capture object
    
    if not ret:
        print(f"Error: Could not read frame {nthFrame}")
        return None, None

    # Convert frame to RGB and grayscale
    original_img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    gray_img = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)

    # Ensure binary mask is uint8 (0 and 255)
    binary_mask = binary_mask.astype(np.uint8)
    
    # Compute distance transform
    dist_transform = cv2.distanceTransform(binary_mask, cv2.DIST_L2, 5)
    
    # Detect peaks (markers)
    min_distance = int(_w1.Entry20.get())  # Get min distance from GUI
    coords = peak_local_max(
        dist_transform,
        min_distance=min_distance,
        labels=binary_mask,
        exclude_border=False
    )
    
    # Create markers image
    markers = np.zeros_like(binary_mask, dtype=np.int32)
    for i, (y, x) in enumerate(coords, start=1):
        markers[y, x] = i
    
    # Apply watershed
    labels = watershed(-dist_transform, markers, mask=binary_mask)
    
    # Calculate region properties
    props = regionprops_table(
        labels, 
        gray_img,
        properties=(
            'label',
            'area',
            'eccentricity',
            'mean_intensity',
            'centroid'
        )
    )
    
    # Convert to DataFrame
    df = pd.DataFrame(props)
    df['std_intensity'] = regionprops_table(
        labels, 
        gray_img,
        properties=('intensity_std',)
    )['intensity_std']
    
    # Rename columns for clarity
    df = df.rename(columns={
        'label': 'Particle ID',
        'area': 'Area (px)',
        'eccentricity': 'Eccentricity',
        'mean_intensity': 'Mean Intensity',
        'std_intensity': 'Std Intensity',
        'centroid-0': 'Y Position',
        'centroid-1': 'X Position'
    })
    
    # Save to Excel in the same directory as the video
    excel_path = os.path.join(pathMovie, 'watershed_results.xlsx')
    df.to_excel(excel_path, index=False)

    plt.figure(1, figsize=(10, 10))
    watershed_display = np.zeros((labels.shape[0], labels.shape[1], 3), dtype=np.uint8)
    for label in np.unique(labels):
        if label == 0:
            continue
        mask = labels == label
        watershed_display[mask] = np.random.randint(0, 255, size=3)
    
    blended = cv2.addWeighted(original_img, 0.7, watershed_display, 0.3, 0)
    plt.imshow(blended)
    plt.title(f'Watershed Segmentation - {len(df)} Particles Detected (Frame {nthFrame})')
    plt.axis('off')

    plt.figure(2, figsize=(10, 10))
    plt.imshow(watershed_display)
    for _, row in df.iterrows():
        y, x = row['Y Position'], row['X Position']
        plt.text(
            x, y, str(int(row['Particle ID'])),
            color='white', fontsize=8, fontweight='bold',
            ha='center', va='center',
            bbox=dict(facecolor='black', alpha=0.7, edgecolor='none', boxstyle='round,pad=0.2')
        )
    plt.title(f'Numbered Particles - Frame {nthFrame}')
    plt.axis('off')

    fig3 = plt.figure(3, figsize=(12, 8))
    ax_table = fig3.add_subplot(111)
    ax_table.axis('off')
    
    table_data = df.drop(['X Position', 'Y Position'], axis=1).round({
        'Area (px)': 1,
        'Eccentricity': 4,
        'Mean Intensity': 1,
        'Std Intensity': 1
    })
    
    visible_rows = min(15, len(df))
    table = ax_table.table(
        cellText=table_data.head(visible_rows).values,
        colLabels=table_data.columns,
        loc='center',
        cellLoc='center'
    )
    
    table.auto_set_font_size(False)
    table.set_fontsize(9)
    table.scale(1, 1.2)
    plt.subplots_adjust(bottom=0.2)
    
    if len(df) > 15:
        from matplotlib.widgets import Slider
        ax_slider = plt.axes([0.25, 0.1, 0.5, 0.03], facecolor='lightgoldenrodyellow')
        slider = Slider(ax_slider, 'Scroll Table', 0, len(df)-15, valinit=0, valstep=1)
        
        def update_table(val):
            start = int(val)
            end = start + 15
            visible_data = table_data.iloc[start:end]
            for i in range(len(visible_data)+1):
                for j, col in enumerate(table_data.columns):
                    cell = table[(i, j)]
                    if i == 0:
                        cell.get_text().set_text(col)
                    else:
                        cell.get_text().set_text(str(visible_data.iloc[i-1, j]))
            fig3.canvas.draw_idle()
        
        slider.on_changed(update_table)
        update_table(0)
    
    plt.suptitle(f'Particle Measurements - Frame {nthFrame}', y=0.98)
    plt.show()
    
    return labels, df

#-----------------------------------------------------------------------------
def f_CrossSectOrig(*args):
    global frame_first_gray
    print('Cross Section button pressed')
    
    # Load image
    I = frame_first_gray.copy()
    
    # Ensure image is grayscale (2D array)
    if len(I.shape) == 3:  # If it's a color image
        I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)
    
    # Create figure and display image
    fig, ax = plt.subplots(figsize=(10, 6))
    ax.imshow(I, cmap='gray')
    ax.set_title('Click two points to define a line (first then second)')
    
    # Variables to store clicked points
    points = []
    
    def on_click(event):
        if event.inaxes == ax:
            if event.button == 1:  # Left mouse button
                x, y = int(event.xdata), int(event.ydata)
                points.append((x, y))
                ax.plot(x, y, 'ro', markersize=4)
                
                # Draw line if two points are selected
                if len(points) == 2:
                    x1, y1 = points[0]
                    x2, y2 = points[1]
                    ax.plot([x1, x2], [y1, y2], 'r-', linewidth=2)
                    fig.canvas.draw()
                    
                    # Extract and display cross-section
                    extract_cross_section(I, points[0], points[1])
                    
                    # Disconnect the event after two clicks
                    fig.canvas.mpl_disconnect(cid)
    
    # Connect the click event
    cid = fig.canvas.mpl_connect('button_press_event', on_click)
    plt.show()

def extract_cross_section(image, point1, point2):
    """Extract intensity profile along a line between two points"""
    x1, y1 = point1
    x2, y2 = point2
    
    # Get number of points for the line
    length = int(np.sqrt((x2 - x1)**2 + (y2 - y1)**2))
    
    # Get coordinates along the line
    x = np.linspace(x1, x2, length)
    y = np.linspace(y1, y2, length)
    
    # Extract intensity values (using nearest neighbor interpolation)
    intensities = []
    for i in range(length):
        xi, yi = int(round(x[i])), int(round(y[i]))
        # Ensure coordinates are within image bounds
        if 0 <= xi < image.shape[1] and 0 <= yi < image.shape[0]:
            intensities.append(image[yi, xi])
        else:
            intensities.append(0)  # Outside bounds
    
    # Create cross-section plot
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
    
    # Show original image with line
    ax1.imshow(image, cmap='gray')
    ax1.plot([x1, x2], [y1, y2], 'r-', linewidth=2)
    ax1.plot(x1, y1, 'go', markersize=6, label='Start')
    ax1.plot(x2, y2, 'bo', markersize=6, label='End')
    ax1.set_title('Selected Line on Image')
    ax1.legend()
    
    # Show intensity profile
    ax2.plot(intensities, 'b-', linewidth=1.5)
    ax2.set_xlabel('Distance along line (pixels)')
    ax2.set_ylabel('Intensity')
    ax2.set_title('Cross-Section Intensity Profile')
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    print(f"Line from ({x1}, {y1}) to ({x2}, {y2})")
    print(f"Line length: {length} pixels")
    print(f"Intensity range: {np.min(intensities)} - {np.max(intensities)}")
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_SelectByThresholding(*args):
    global frame_first_gray, filteredTemp

    print('SelectByThresholding button pressed')

    lowerLimit = int(_w1.Entry21.get())
    upperLimit = int(_w1.Entry22.get())

    # Load image
    I = frame_first_gray.copy()
    
    # Ensure image is grayscale (2D array)
    if len(I.shape) == 3:
        I = cv2.cvtColor(I, cv2.COLOR_BGR2GRAY)
    
    # Validate input range
    if lowerLimit > upperLimit:
        lowerLimit, upperLimit = upperLimit, lowerLimit
        print(f"Warning: Limits swapped. Using range: {lowerLimit}-{upperLimit}")
    
    if lowerLimit < 0:
        lowerLimit = 0
        print("Warning: Lower limit adjusted to 0")
    
    if upperLimit > 255:
        upperLimit = 255
        print("Warning: Upper limit adjusted to 255")
    
    # Create mask using inRange function
    mask = cv2.inRange(I, lowerLimit, upperLimit)
    
    # Optional: Apply morphological operations to clean up the mask
    # kernel = np.ones((3, 3), np.uint8)
    # mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)  # Remove small noise
    # mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)  # Fill small holes
    
    # Store the result
    filteredTemp = mask.copy()
    
    # Display results
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Original image
    axes[0].imshow(I, cmap='gray')
    axes[0].set_title('Original Image')
    axes[0].axis('off')
    
    # Mask
    axes[1].imshow(mask, cmap='gray')
    axes[1].set_title(f'Mask ({lowerLimit}-{upperLimit})')
    axes[1].axis('off')
    
    # Overlay (optional)
    overlay = I.copy()
    if len(overlay.shape) == 2:
        overlay = cv2.cvtColor(overlay, cv2.COLOR_GRAY2BGR)
    overlay[mask == 255] = [0, 255, 0]  # Highlight selected areas in green
    
    axes[2].imshow(overlay)
    axes[2].set_title('Selected Areas (Green)')
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.show()
    
    # Print statistics
    total_pixels = mask.size
    selected_pixels = np.sum(mask == 255)
    percentage = (selected_pixels / total_pixels) * 100
    
    print(f"Intensity range: {lowerLimit} - {upperLimit}")
    print(f"Selected pixels: {selected_pixels} ({percentage:.2f}% of image)")
    print(f"Excluded pixels: {total_pixels - selected_pixels}")
    
    # return mask
#-----------------------------------------------------------------------------

#-----------------------------------------------------------------------------
def f_ViolinPlots(*args):
    
    #Create violin plots for cell displacement analysis in separate windows.
    #Handles any number of cells by creating multiple windows with max 12 plots each.
    
    print("=== VIOLIN PLOT FUNCTION CALLED ===")
    
    try:
        # Use global blob_properties
        global global_blob_properties
        
        print(f"Global data exists: {global_blob_properties is not None}")
        
        if not global_blob_properties:
            print("ERROR: No tracking data available")
            messagebox.showerror("Error", "Please run blob tracking analysis first.")
            return
        
        print(f"Found {len(global_blob_properties)} cells")
        
        # Get number of segments from GUI or use default
        try:
            nbOfViolins = int(_w1.Entry30.get())
            print(f"Using {nbOfViolins} segments")
        except:
            nbOfViolins = 4
            print(f"Using default {nbOfViolins} segments")
        
        # Get all cell IDs
        cell_ids = sorted(global_blob_properties.keys())
        total_cells = len(cell_ids)
        
        # Split cells into groups of maximum 12 per window
        max_cells_per_window = 12
        num_windows = (total_cells + max_cells_per_window - 1) // max_cells_per_window
        
        print(f"Creating {num_windows} windows with max {max_cells_per_window} cells each")
        
        for window_idx in range(num_windows):
            start_idx = window_idx * max_cells_per_window
            end_idx = min((window_idx + 1) * max_cells_per_window, total_cells)
            
            window_cell_ids = cell_ids[start_idx:end_idx]
            print(f"Window {window_idx + 1}: Cells {window_cell_ids}")
            
            # Create new figure for this window
            fig = plt.figure(window_idx + 1, figsize=(15, 10))
            fig.canvas.manager.set_window_title(f'Cell Displacements - Window {window_idx + 1}')
            
            # Calculate grid layout
            n_cells_in_window = len(window_cell_ids)
            n_cols = min(3, n_cells_in_window)  # Max 3 columns
            n_rows = (n_cells_in_window + n_cols - 1) // n_cols
            
            # Create subplots
            for idx, cell_id in enumerate(window_cell_ids):
                ax = plt.subplot(n_rows, n_cols, idx + 1)
                
                displacements = global_blob_properties[cell_id]['displacements']
                
                # Skip first frame if it's zero (starting position)
                if len(displacements) > 1 and displacements[0] == 0:
                    displacements = displacements[1:]
                
                if not displacements:
                    ax.text(0.5, 0.5, f'Cell {cell_id}\nNo displacement data', 
                           transform=ax.transAxes, ha='center', va='center', fontsize=12)
                    ax.set_title(f'Cell {cell_id}', fontweight='bold')
                    continue
                
                # Split data into segments for the violin plot
                segment_displacements = []
                segment_labels = []
                
                if nbOfViolins > 1 and len(displacements) >= nbOfViolins:
                    frames_per_segment = len(displacements) // nbOfViolins
                    
                    for i in range(nbOfViolins):
                        start_frame = i * frames_per_segment
                        end_frame = (i + 1) * frames_per_segment if i < nbOfViolins - 1 else len(displacements)
                        segment_data = displacements[start_frame:end_frame]
                        
                        if segment_data:
                            segment_displacements.append(segment_data)
                            segment_labels.append(f'Seg {i+1}')
                else:
                    # Use all data as one segment
                    segment_displacements = [displacements]
                    segment_labels = ['All']
                
                # Create violin plot
                if segment_displacements:
                    violins = ax.violinplot(segment_displacements, 
                                          showmeans=True, 
                                          showmedians=True,
                                          showextrema=True)
                    
                    # Customize violin plot colors
                    for pc in violins['bodies']:
                        pc.set_facecolor('#1f77b4')
                        pc.set_alpha(0.7)
                    
                    # Customize other plot elements
                    violins['cmeans'].set_color('red')
                    violins['cmedians'].set_color('orange')
                    
                    ax.set_title(f'Cell {cell_id}', fontweight='bold', fontsize=12)
                    ax.set_ylabel('Displacement (pixels)', fontsize=10)
                    ax.set_xlabel('Time Segment', fontsize=10)
                    
                    # Set x-axis labels
                    if segment_labels:
                        ax.set_xticks(range(1, len(segment_labels) + 1))
                        ax.set_xticklabels(segment_labels)
                    
                    ax.grid(True, alpha=0.3, axis='y')
                    
                    # Add statistics text
                    mean_disp = np.mean(displacements)
                    max_disp = np.max(displacements)
                    ax.text(0.02, 0.98, f'Mean: {mean_disp:.2f}\nMax: {max_disp:.2f}', 
                           transform=ax.transAxes, va='top', ha='left', 
                           bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),
                           fontsize=9)
            
            # Adjust layout and show this window
            plt.suptitle(f'Cell Displacement Distribution - Cells {start_idx + 1} to {end_idx} '
                        f'({nbOfViolins} Time Segments)', fontsize=14, fontweight='bold')
            plt.tight_layout()
            plt.subplots_adjust(top=0.93)
            
            # Show this window (non-blocking for multiple windows)
            plt.show(block=False)
        
        print(f"Successfully created {num_windows} violin plot windows!")
        
        # Message to user
        if num_windows > 1:
            messagebox.showinfo("Violin Plots Created", 
                              f"Created {num_windows} separate windows with violin plots.\n"
                              f"Each window shows up to {max_cells_per_window} cells.")
        
    except Exception as e:
        print(f"ERROR in violin plots: {type(e).__name__}: {str(e)}")
        import traceback
        traceback.print_exc()
        messagebox.showerror("Error", f"Failed to create violin plots:\n{str(e)}")

#-----------------------------------------------------------------------------

"""
#---------------------------------------------------
def test_violin_plots():
    #Test function to create sample violin plots with dummy data
    print("Creating test violin plots...")
    
    # Create dummy blob properties for testing
    dummy_blob_properties = {
        1: {
            'displacements': [0, 1.2, 0.8, 1.5, 0.9, 1.1, 0.7, 1.3, 0.6, 1.4] * 10
        },
        2: {
            'displacements': [0, 0.5, 0.9, 0.3, 0.7, 0.8, 0.4, 0.6, 0.2, 0.5] * 10
        },
        3: {
            'displacements': [0, 2.1, 1.8, 2.3, 1.9, 2.0, 1.7, 2.2, 1.6, 2.4] * 10
        }
    }
    
    # Add required properties
    for blob_id in dummy_blob_properties:
        displacements = dummy_blob_properties[blob_id]['displacements']
        dummy_blob_properties[blob_id]['areas'] = [100] * len(displacements)
        dummy_blob_properties[blob_id]['total_displacement'] = sum(displacements[1:])
    
    # Call the violin plot function directly
    f_Blobs_Displ_ViolinPlot(dummy_blob_properties)
    print("Test completed - you should see violin plots now!")
#----------------------------------------------------
"""



#----------------------------------------------------
def f_Debug_Blob_Data(*args):
    """Debug function to check blob data"""
    global global_blob_properties
    print("=== DEBUG BLOB DATA ===")
    print(f"global_blob_properties: {global_blob_properties}")
    if global_blob_properties:
        print(f"Number of cells: {len(global_blob_properties)}")
        for cell_id, props in list(global_blob_properties.items())[:3]:  # First 3 cells
            print(f"Cell {cell_id}: {len(props.get('displacements', []))} displacements")
            if 'displacements' in props:
                print(f"  Sample displacements: {props['displacements'][:5]}...")
    else:
        print("No blob data available - run tracking analysis first!")

#----------------------------------------------------

if __name__ == '__main__':
    PyONMD_Ana_02.start_up()

    # Add this line to test violin plots automatically when program starts
    # Uncomment the next line to test:
    #test_violin_plots()





